---
title: 記憶體最佳化資料表的持久性 | Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: in-memory-oltp
ms.topic: conceptual
ms.assetid: d304c94d-3ab4-47b0-905d-3c8c2aba9db6
author: CarlRabeler
ms.author: carlrab
ms.openlocfilehash: 1d48d671b23d7b7b17557e7829d6f2522c375acd
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 08/04/2020
ms.locfileid: "87706513"
---
# <a name="durability-for-memory-optimized-tables"></a><span data-ttu-id="3a363-102">記憶體最佳化資料表的持久性</span><span class="sxs-lookup"><span data-stu-id="3a363-102">Durability for Memory-Optimized Tables</span></span>
  [!INCLUDE[hek_2](../../../includes/hek-2-md.md)] <span data-ttu-id="3a363-103">為記憶體最佳化的資料表提供完整的持久性。</span><span class="sxs-lookup"><span data-stu-id="3a363-103">provides full durability for memory-optimized tables.</span></span> <span data-ttu-id="3a363-104">當變更記憶體最佳化資料表的交易認可時， [!INCLUDE[ssNoVersion](../../../includes/ssnoversion-md.md)] (對磁碟基礎的資料表也一樣) 會保證這些變更是永久的 (即使資料庫重新啟動後也會存在)，前提是要提供基礎儲存。</span><span class="sxs-lookup"><span data-stu-id="3a363-104">When a transaction that changed a memory-optimized table commits, [!INCLUDE[ssNoVersion](../../../includes/ssnoversion-md.md)] (as it does for disk-based tables), guarantees that the changes are permanent (will survive a database restart), provided the underlying storage is available.</span></span> <span data-ttu-id="3a363-105">持久性有兩個重要元件：交易記錄及磁碟儲存的保存資料變更。</span><span class="sxs-lookup"><span data-stu-id="3a363-105">There are two key components of durability: transaction logging and persisting data changes to on-disk storage.</span></span>

## <a name="transaction-log"></a><span data-ttu-id="3a363-106">交易記錄</span><span class="sxs-lookup"><span data-stu-id="3a363-106">Transaction Log</span></span>
 <span data-ttu-id="3a363-107">磁碟基礎的資料表或持久記憶體最佳化資料表的所有變更，都可以在一個或多個交易記錄檔記錄上擷取。</span><span class="sxs-lookup"><span data-stu-id="3a363-107">All changes made to disk-based tables or durable memory-optimized tables are captured in one or more transaction log records.</span></span> <span data-ttu-id="3a363-108">當交易認可時， [!INCLUDE[ssNoVersion](../../../includes/ssnoversion-md.md)] 會將與交易相關聯的記錄檔記錄寫入磁碟，然後才與交易已認可之應用程式或使用者工作階段進行通訊。</span><span class="sxs-lookup"><span data-stu-id="3a363-108">When a transaction commits, [!INCLUDE[ssNoVersion](../../../includes/ssnoversion-md.md)] writes the log records associated with the transaction to disk before communicating to the application or user session that the transaction has committed.</span></span> <span data-ttu-id="3a363-109">這樣可保證交易所做的變更是持久的。</span><span class="sxs-lookup"><span data-stu-id="3a363-109">This guarantees that changes made by the transaction are durable.</span></span> <span data-ttu-id="3a363-110">記憶體最佳化資料表的交易記錄檔會與磁碟資料表所使用的相同記錄檔資料流完全整合在一起。</span><span class="sxs-lookup"><span data-stu-id="3a363-110">The transaction log for memory-optimized tables is fully integrated with the same log stream used by disk-based tables.</span></span> <span data-ttu-id="3a363-111">這項整合允許現有的交易記錄檔備份、復原及還原作業繼續運作，而不需要進行其他任何步驟。</span><span class="sxs-lookup"><span data-stu-id="3a363-111">This integration allows existing transaction log backup, recover, and restore operations to continue to work without requiring any additional steps.</span></span> <span data-ttu-id="3a363-112">不過，因為 [!INCLUDE[hek_2](../../../includes/hek-2-md.md)] 會大幅增加工作負載的交易輸送量，所以您需要確定交易記錄檔儲存體的設定正確，以處理增加的 IO 需求。</span><span class="sxs-lookup"><span data-stu-id="3a363-112">However, since [!INCLUDE[hek_2](../../../includes/hek-2-md.md)] can increase transaction throughput of your workload significantly, you need to make sure that transaction log storage is configured appropriately to handle the increased IO requirements.</span></span>

## <a name="data-and-delta-files"></a><span data-ttu-id="3a363-113">資料和差異檔案</span><span class="sxs-lookup"><span data-stu-id="3a363-113">Data and Delta Files</span></span>
 <span data-ttu-id="3a363-114">記憶體最佳化資料表中的資料會在記憶體中儲存為自由格式的資料列，並透過一個或多個記憶體中的索引加以連結。</span><span class="sxs-lookup"><span data-stu-id="3a363-114">The data in memory-optimized tables is stored as free-form data rows that are linked through one or more in-memory indexes, in memory.</span></span> <span data-ttu-id="3a363-115">資料列沒有任何頁面結構，例如用於磁碟基礎的資料表頁面結構。</span><span class="sxs-lookup"><span data-stu-id="3a363-115">There are no page structures for data rows, such as those used for disk-based tables.</span></span> <span data-ttu-id="3a363-116">當應用程式準備認可交易時，[!INCLUDE[hek_2](../../../includes/hek-2-md.md)] 會產生交易的記錄檔記錄。</span><span class="sxs-lookup"><span data-stu-id="3a363-116">When the application is ready to commit the transaction, the [!INCLUDE[hek_2](../../../includes/hek-2-md.md)] generates the log records for the transaction.</span></span> <span data-ttu-id="3a363-117">記憶體最佳化的資料表持續性會透過一組資料和差異檔案使用背景執行緒完成。</span><span class="sxs-lookup"><span data-stu-id="3a363-117">The persistence of memory-optimized tables is done with a set of data and delta files using a background thread.</span></span> <span data-ttu-id="3a363-118">資料和差異檔案位於一個或多個容器 (和 FILESTREAM 資料使用相同的機制)。</span><span class="sxs-lookup"><span data-stu-id="3a363-118">The data and delta files are located in one or more containers (using the same mechanism used for FILESTREAM data).</span></span> <span data-ttu-id="3a363-119">這些容器會對應到新的檔案群組類型，稱為記憶體最佳化的檔案群組。</span><span class="sxs-lookup"><span data-stu-id="3a363-119">These containers are mapped to a new type of filegroup, called a memory-optimized filegroup.</span></span>

 <span data-ttu-id="3a363-120">資料會遵循嚴格的順序寫入，使轉動式媒體的磁碟延遲減到最少。</span><span class="sxs-lookup"><span data-stu-id="3a363-120">Data is written to these files in a strictly sequential fashion, which minimizes disk latency for spinning media.</span></span> <span data-ttu-id="3a363-121">您可以在不同的磁碟上使用多個容器以散發 I/O 活動。</span><span class="sxs-lookup"><span data-stu-id="3a363-121">You can use multiple containers on different disks to distribute the I/O activity.</span></span> <span data-ttu-id="3a363-122">從磁碟上的資料檔案和差異檔案將資料讀入記憶體時，不同磁碟上多個容器內的資料檔案和差異檔案將會提升復原效能。</span><span class="sxs-lookup"><span data-stu-id="3a363-122">Data and delta files in multiple containers on different disks will increase recovery performance when data is read from the data and delta files on disk, into memory.</span></span>

 <span data-ttu-id="3a363-123">應用程式不會直接存取資料和差異檔案。</span><span class="sxs-lookup"><span data-stu-id="3a363-123">An application does not directly access data and delta files.</span></span> <span data-ttu-id="3a363-124">所有資料讀取和寫入皆使用記憶體中資料。</span><span class="sxs-lookup"><span data-stu-id="3a363-124">All data reads and writes use in-memory data.</span></span>

### <a name="the-data-file"></a><span data-ttu-id="3a363-125">資料檔案</span><span class="sxs-lookup"><span data-stu-id="3a363-125">The Data File</span></span>
 <span data-ttu-id="3a363-126">資料檔案包含了由 INSERT 或 UPDATE 作業中的多筆交易所插入的一個或多個記憶體最佳化資料表而來的資料列。</span><span class="sxs-lookup"><span data-stu-id="3a363-126">A data file contains rows from one or more memory-optimized tables that were inserted by multiple transactions as part of INSERT or UPDATE operations.</span></span> <span data-ttu-id="3a363-127">例如，某個資料列可能來自記憶體最佳化資料表 T1，而下一個資料列可能來自記憶體最佳化資料表 T2。</span><span class="sxs-lookup"><span data-stu-id="3a363-127">For example, one row can be from memory-optimized table T1 and the next row can be from memory-optimized table T2.</span></span> <span data-ttu-id="3a363-128">資料列會以交易記錄中的交易順序附加到資料檔案，好讓資料存取循序進行。</span><span class="sxs-lookup"><span data-stu-id="3a363-128">The rows are appended to the data file in the order of transactions in the transaction log, making data access sequential.</span></span> <span data-ttu-id="3a363-129">相較於隨機 I/O，這樣的重要性順序會產生較佳的 I/O 輸送量。</span><span class="sxs-lookup"><span data-stu-id="3a363-129">This enables an order of magnitude better I/O throughput compared to random I/O.</span></span> <span data-ttu-id="3a363-130">若為記憶體大於 16GB 的電腦，每個資料檔案的大小約為 128MB；若為記憶體小於或等於 16GB 的電腦，每個資料檔案的大小約為 16MB。</span><span class="sxs-lookup"><span data-stu-id="3a363-130">Each data file is sized approximately to 128MB for computers with memory greater than 16GB, and 16MB for computers with less than or equal to 16GB.</span></span> <span data-ttu-id="3a363-131">一旦資料檔案已滿，新交易所插入的資料列將會儲存至另一個資料檔案。</span><span class="sxs-lookup"><span data-stu-id="3a363-131">Once the data file is full, the rows inserted by new transactions are stored in another data file.</span></span> <span data-ttu-id="3a363-132">經過一段時間後，從持久的記憶體最佳化資料表而來的資料列將由多個資料檔案各自儲存，每個資料檔案所包含的資料列來自互不相交但屬連續範圍的交易。</span><span class="sxs-lookup"><span data-stu-id="3a363-132">Over time, the rows from durable memory-optimized tables are stored in one of more data files and each data file containing rows from a disjoint but contiguous range of transactions.</span></span> <span data-ttu-id="3a363-133">例如，交易認可時間戳記範圍為 (100, 200) 的資料檔案，包含交易 (具有大於 100 及小於或等於 200 的認可時間戳記) 所插入的所有資料列。</span><span class="sxs-lookup"><span data-stu-id="3a363-133">For example a data file with transaction commit timestamp in the range of (100, 200) has all the rows inserted by transactions that have commit timestamp greater than 100 and less than or equal to 200.</span></span> <span data-ttu-id="3a363-134">認可時間戳記是交易在準備認可時獲指派的一個單純遞增數字。</span><span class="sxs-lookup"><span data-stu-id="3a363-134">The commit timestamp is a monotonically increasing number assigned to a transaction when it is ready to commit.</span></span> <span data-ttu-id="3a363-135">每筆交易都有其獨一無二的認可時間戳記。</span><span class="sxs-lookup"><span data-stu-id="3a363-135">Each transaction has a unique commit timestamp.</span></span>

 <span data-ttu-id="3a363-136">當資料列遭到刪除或更新時，並不會就地移除或變更資料檔案中的該資料列，而是在另一類型的檔案中追蹤已刪除的資料列：差異檔案。</span><span class="sxs-lookup"><span data-stu-id="3a363-136">When a row is deleted or updated, the row is not removed or changed in-place in the data file but the deleted rows are tracked in another type of file: the delta file.</span></span> <span data-ttu-id="3a363-137">每個資料列的刪除和插入作業將統整為 Tuple，藉此處理更新作業。</span><span class="sxs-lookup"><span data-stu-id="3a363-137">Update operations are processed as a tuple of delete and insert operations for each row.</span></span> <span data-ttu-id="3a363-138">這可使資料檔案排除隨機 IO。</span><span class="sxs-lookup"><span data-stu-id="3a363-138">This eliminates random IO on the data file.</span></span>

### <a name="the-delta-file"></a><span data-ttu-id="3a363-139">差異檔案</span><span class="sxs-lookup"><span data-stu-id="3a363-139">The Delta File</span></span>
 <span data-ttu-id="3a363-140">每一個資料檔案皆會與具有相同交易範圍，且將追蹤由該交易範圍內的交易所插入之已刪除資料列的差異檔案進行配對。</span><span class="sxs-lookup"><span data-stu-id="3a363-140">Each data file is paired with a delta file that has the same transaction range and tracks the deleted rows inserted by transactions in the transaction range.</span></span> <span data-ttu-id="3a363-141">這種資料和差異檔案稱為檢查點檔案組 (CFP)，並為配置、取消配置與合併作業的單位。</span><span class="sxs-lookup"><span data-stu-id="3a363-141">This data and delta file is referred to as a Checkpoint File Pair (CFP) and it is the unit of allocation and deallocation as well as the unit for Merge operations.</span></span> <span data-ttu-id="3a363-142">例如，與交易範圍 (100, 200) 對應的差異檔案會儲存由範圍 (100, 200) 內的交易所插入的已刪除資料列。</span><span class="sxs-lookup"><span data-stu-id="3a363-142">For example, a delta file corresponding to transaction range (100, 200) will store deleted rows that were inserted by transactions in the range (100, 200).</span></span> <span data-ttu-id="3a363-143">就像資料檔案，對差異檔案的存取也是循序進行。</span><span class="sxs-lookup"><span data-stu-id="3a363-143">Like data files, the delta file is accessed sequentially.</span></span>

 <span data-ttu-id="3a363-144">當資料列遭到刪除時，並不會從資料檔案移除該資料列，而是該資料列的參考將附加到與該資料列插入當時的交易範圍相關聯的差異檔案。</span><span class="sxs-lookup"><span data-stu-id="3a363-144">When a row is deleted, the row is not removed from the data file but a reference to the row is appended to the delta file associated with the transaction range where this data row was inserted.</span></span> <span data-ttu-id="3a363-145">由於要刪除的資料列已存在於資料檔案中，差異檔案只會儲存參考資訊 `{inserting_tx_id, row_id, deleting_tx_id }` ，且將遵照原始刪除或更新作業的交易記錄順序。</span><span class="sxs-lookup"><span data-stu-id="3a363-145">Since the row to be deleted already exists in the data file, the delta file only stores the reference information `{inserting_tx_id, row_id, deleting_tx_id }` and it follows the transactional log order of the originating delete or update operations.</span></span>

## <a name="populating-data-and-delta-files"></a><span data-ttu-id="3a363-146">擴展資料檔案和差異檔案</span><span class="sxs-lookup"><span data-stu-id="3a363-146">Populating Data and Delta Files</span></span>
 <span data-ttu-id="3a363-147">資料檔案和差異檔案是由稱為離線檢查點的背景執行緒所擴展。</span><span class="sxs-lookup"><span data-stu-id="3a363-147">Data and delta file are populated by a background thread called offline checkpoint.</span></span> <span data-ttu-id="3a363-148">此執行緒會讀取記憶體最佳化資料表已認可之交易所產生的交易記錄，再將已插入及刪除的資料列相關資訊附加到適當的資料檔案和差異檔案。</span><span class="sxs-lookup"><span data-stu-id="3a363-148">This thread reads the transaction log records generated by committed transactions on memory-optimized tables and appends information about the inserted and deleted rows into appropriate data and delta files.</span></span> <span data-ttu-id="3a363-149">不同於在檢查點完成時以隨機 I/O 方式排清資料/索引頁的磁碟資料表，記憶體最佳化資料表的保存是連續的背景作業。</span><span class="sxs-lookup"><span data-stu-id="3a363-149">Unlike disk-based tables where data/index pages are flushed with random I/O when checkpoint is done, the persistence of memory-optimized table is continuous background operation.</span></span> <span data-ttu-id="3a363-150">如此將會存取多個差異檔案，因為交易可以刪除或更新任何先前交易所插入的任何資料列。</span><span class="sxs-lookup"><span data-stu-id="3a363-150">Multiple delta files are accessed because a transaction can delete or update any row that was inserted by any previous transaction.</span></span> <span data-ttu-id="3a363-151">刪除資訊一律會附加到差異檔案的結尾。</span><span class="sxs-lookup"><span data-stu-id="3a363-151">Deletion information is always appended at the end of the delta file.</span></span> <span data-ttu-id="3a363-152">例如，認可時間戳記為 600 的交易會插入一個新的資料列，並且刪除認可時間戳記為 150、250 和 450 的交易所插入的資料列，如下圖所示。</span><span class="sxs-lookup"><span data-stu-id="3a363-152">For example, a transaction with a commit timestamp of 600 inserts one new row and deletes rows inserted by transactions with a commit timestamp of 150, 250 and 450 as shown in the picture below.</span></span> <span data-ttu-id="3a363-153">所有 4 個檔案 I/O 作業 (三個用於已刪除的資料列，一個用於新插入的資料列) 都是對應的差異檔案和資料檔案的附加專用作業。</span><span class="sxs-lookup"><span data-stu-id="3a363-153">All 4 file I/O operations (three for deleted rows and 1 for the newly inserted rows), are append-only operations to the corresponding delta and data files.</span></span>

 <span data-ttu-id="3a363-154">![讀取記憶體最佳化資料表的記錄檔記錄。](../../database-engine/media/read-logs-hekaton.gif "讀取記憶體最佳化資料表的記錄檔記錄。")</span><span class="sxs-lookup"><span data-stu-id="3a363-154">![Read log records for memory-optimized tables.](../../database-engine/media/read-logs-hekaton.gif "Read log records for memory-optimized tables.")</span></span>

## <a name="accessing-data-and-delta-files"></a><span data-ttu-id="3a363-155">存取資料和差異檔案</span><span class="sxs-lookup"><span data-stu-id="3a363-155">Accessing Data and Delta Files</span></span>
 <span data-ttu-id="3a363-156">在發生以下情況時，將會存取資料檔案和差異檔案組。</span><span class="sxs-lookup"><span data-stu-id="3a363-156">Data and delta file pairs are accessed when the following occurs.</span></span>

 <span data-ttu-id="3a363-157">離線檢查點執行緒此執行緒會將記憶體優化資料列中的插入和刪除附加至對應的資料檔案和差異檔案組。</span><span class="sxs-lookup"><span data-stu-id="3a363-157">Offline checkpoint thread This thread appends inserts and deletes to memory-optimized data rows, to the corresponding data and delta file pairs.</span></span>

 <span data-ttu-id="3a363-158">合併作業：作業會合並一或多個資料和差異檔案組，並建立新的資料檔案和差異檔案組。</span><span class="sxs-lookup"><span data-stu-id="3a363-158">Merge operation The operation merges one or more data and delta file pairs and creates a new data and delta file pair.</span></span>

 <span data-ttu-id="3a363-159">當 [!INCLUDE[ssNoVersion](../../../includes/ssnoversion-md.md)] 重新開機或資料庫恢復連線時，當機復原期間，會使用資料檔案和差異檔案組來填入記憶體優化資料。</span><span class="sxs-lookup"><span data-stu-id="3a363-159">During crash recovery When [!INCLUDE[ssNoVersion](../../../includes/ssnoversion-md.md)] is restarted or the database is brought back online, the memory-optimized data is populated using the data and delta file pairs.</span></span> <span data-ttu-id="3a363-160">從對應的資料檔案讀取資料列時，差異檔案會當做已刪除之資料列的篩選條件。</span><span class="sxs-lookup"><span data-stu-id="3a363-160">The delta file acts as a filter for the deleted rows when reading the rows from the corresponding data file.</span></span> <span data-ttu-id="3a363-161">因為每個資料和差異檔案組是獨立的，所以這些檔案會平行載入，以減少將資料擴展到記憶體所花的時間。</span><span class="sxs-lookup"><span data-stu-id="3a363-161">Because each data and delta file pair is independent, these files are loaded in parallel to reduce the time taken to populate data into memory.</span></span> <span data-ttu-id="3a363-162">資料載入記憶體之後，記憶體中 OLTP 引擎會套用檢查點檔案仍未涵蓋的使用中交易記錄，使記憶體最佳化資料完成。</span><span class="sxs-lookup"><span data-stu-id="3a363-162">Once the data has been loaded into memory, the In-Memory OLTP engine applies the active transaction log records not yet covered by the checkpoint files so that the memory-optimized data is complete.</span></span>

 <span data-ttu-id="3a363-163">在還原作業期間，會從資料庫備份建立記憶體內部 OLTP 檢查點檔案，然後套用一或多個交易記錄備份。</span><span class="sxs-lookup"><span data-stu-id="3a363-163">During restore operation The In-Memory OLTP checkpoint files are created from the database backup, and then one or more transaction log backups are applied.</span></span> <span data-ttu-id="3a363-164">就像進行當機復原一樣，記憶體中 OLTP 引擎會將資料平行載入記憶體中，以減少對復原時間的衝擊。</span><span class="sxs-lookup"><span data-stu-id="3a363-164">As with crash recovery, the In-Memory OLTP engine loads data into memory in parallel, to minimize the impact on recovery time.</span></span>

## <a name="merging-data-and-delta-files"></a><span data-ttu-id="3a363-165">合併資料和差異檔案</span><span class="sxs-lookup"><span data-stu-id="3a363-165">Merging Data and Delta Files</span></span>
 <span data-ttu-id="3a363-166">記憶體最佳化資料表的資料是儲存於一個或多個資料檔案和差異檔案組 (又稱為檢查點檔案組或 CFP)。</span><span class="sxs-lookup"><span data-stu-id="3a363-166">The data for memory optimized tables is stored in one or more data and delta file pairs (also called a checkpoint file pair, or CFP).</span></span> <span data-ttu-id="3a363-167">資料檔案會儲存已插入的資料列，而差異檔案將參考已刪除的資料列。</span><span class="sxs-lookup"><span data-stu-id="3a363-167">Data files store inserted rows and delta files reference deleted rows.</span></span> <span data-ttu-id="3a363-168">在執行 OLTP 工作負載期間，隨著 DML 作業更新、插入和刪除資料列，會建立新的 CFP 以保存新資料列，並且將已刪除之資料列的參考附加至差異檔案。</span><span class="sxs-lookup"><span data-stu-id="3a363-168">During the execution of an OLTP workload, as the DML operations update, insert, and delete rows, new CFPs are created to persist the new rows, and the reference to the deleted rows is appended to delta files.</span></span>

 <span data-ttu-id="3a363-169">所有先前已關閉及目前使用中 CFP 的中繼資料都將儲存至稱為儲存體陣列的內部陣列結構。</span><span class="sxs-lookup"><span data-stu-id="3a363-169">The metadata of all previously-closed and currently active CFPs is stored in an internal array structure referred to as the storage array.</span></span> <span data-ttu-id="3a363-170">它是有大小限制的 (8,192 個項目) CFP 陣列。</span><span class="sxs-lookup"><span data-stu-id="3a363-170">It is a finitely sized (8,192 entries) array of CFPs.</span></span> <span data-ttu-id="3a363-171">儲存體陣列中的項目是依交易範圍排序。</span><span class="sxs-lookup"><span data-stu-id="3a363-171">The entries in the storage array are ordered by transaction range.</span></span> <span data-ttu-id="3a363-172">儲存體陣列中的 CFP (連同記錄結尾) 代表使用記憶體最佳化資料表復原資料庫時所需的所有磁碟內存狀態。</span><span class="sxs-lookup"><span data-stu-id="3a363-172">The CFPs in the storage array (along with the tail of the log) represent all the on-disk state required to recover a database with memory-optimized tables.</span></span>

 <span data-ttu-id="3a363-173">經過一段時間後，透過 DML 作業，CFP 數目的成長造成儲存體陣列達到承載容量，導致遇到下列情況：</span><span class="sxs-lookup"><span data-stu-id="3a363-173">Over time, with DML operations, the number of CFPs grow causing the storage array to reach capacity, which introduces the following challenges:</span></span>

-   <span data-ttu-id="3a363-174">已刪除的資料列。</span><span class="sxs-lookup"><span data-stu-id="3a363-174">Deleted rows.</span></span>  <span data-ttu-id="3a363-175">已刪除的資料列仍保留在資料檔案中，但在對應的差異檔案中卻標示為已刪除。</span><span class="sxs-lookup"><span data-stu-id="3a363-175">Deleted rows remain in the data file but are marked as deleted in the corresponding delta file.</span></span> <span data-ttu-id="3a363-176">這些資料列都是不再需要而即將從儲存體移除的項目。</span><span class="sxs-lookup"><span data-stu-id="3a363-176">These rows are no longer needed and will be removed from the storage.</span></span> <span data-ttu-id="3a363-177">如果已刪除的資料列未從 CFP 移除，就會不必要地佔用空間並延緩復原時間。</span><span class="sxs-lookup"><span data-stu-id="3a363-177">If deleted rows were not removed from CFPs, they would use space unnecessarily and make recovery time slower.</span></span>

-   <span data-ttu-id="3a363-178">儲存體陣列已滿。</span><span class="sxs-lookup"><span data-stu-id="3a363-178">Storage array full.</span></span> <span data-ttu-id="3a363-179">一旦配置於儲存體陣列的項目多達 8,000 個 (陣列中的 192 個項目會保留給現有的合併競爭或讓您手動進行合併)，便無法再對持久的記憶體最佳化資料表執行任何新的 DML 交易。</span><span class="sxs-lookup"><span data-stu-id="3a363-179">When there 8,000 entries in the storage array are allocated (192 entries in the array are reserved for existing merges to compete or to allow you to do manual merges), no new DML transactions can be executed on durable memory-optimized tables.</span></span> <span data-ttu-id="3a363-180">屆時將只允許檢查點及合併作業取用剩餘的項目。</span><span class="sxs-lookup"><span data-stu-id="3a363-180">Only checkpoint and merge operations are allowed to consume the remaining entries.</span></span> <span data-ttu-id="3a363-181">這可確保 DML 交易不致填滿此陣列，且陣列中的某些項目將得以保留供合併現有檔案和回收陣列中的空間。</span><span class="sxs-lookup"><span data-stu-id="3a363-181">This ensures that DML transactions do not fill the array and that some entries in the array are reserved to merge existing files and to reclaim space in the array.</span></span>

-   <span data-ttu-id="3a363-182">儲存體陣列操作負擔。</span><span class="sxs-lookup"><span data-stu-id="3a363-182">Storage array manipulation overhead.</span></span> <span data-ttu-id="3a363-183">內部處理序會搜尋儲存體陣列據以執行作業，例如尋找差異檔案從而附加已刪除的資料列相關資訊。</span><span class="sxs-lookup"><span data-stu-id="3a363-183">Internal processes search the storage array for operations such as finding the delta file to append information about a deleted row.</span></span> <span data-ttu-id="3a363-184">這類作業的成本將隨著項目數增多而增加。</span><span class="sxs-lookup"><span data-stu-id="3a363-184">The cost of these operations increases with the number of entries.</span></span>

 <span data-ttu-id="3a363-185">為了避免上列效率不佳的情況，較舊已關閉的 CFP 會依以下所述的合併原則進行合併，使儲存體陣列壓縮後的 CFP 數目減少但仍代表相同的資料集。</span><span class="sxs-lookup"><span data-stu-id="3a363-185">To help prevent these inefficiencies, the older closed CFPs are merged, based on a merge policy described below, so the storage array is compacted to represent the same set of data, with a reduced number of CFPs.</span></span>

 <span data-ttu-id="3a363-186">資料庫中所有持久資料表的記憶體中大小總計不應該超過 250 GB。</span><span class="sxs-lookup"><span data-stu-id="3a363-186">The total in-memory size of all durable tables in a database should not exceed 250 GB.</span></span> <span data-ttu-id="3a363-187">使用高達 250GB 記憶體的持久資料表，將需要平均 500 GB 的儲存空間 (假設有插入、刪除和更新等作業)。</span><span class="sxs-lookup"><span data-stu-id="3a363-187">Durable tables that use up to 250 GB of memory will, assuming insert, delete, and update operations, require on average 500 GB of storage space.</span></span> <span data-ttu-id="3a363-188">記憶體最佳化的檔案群組中需要 4,000 個資料和差異檔案組，才能支援 500 GB 的儲存空間。</span><span class="sxs-lookup"><span data-stu-id="3a363-188">4,000 data and delta file pairs in the memory-optimized file group are required to support the 500 GB of storage space.</span></span>

 <span data-ttu-id="3a363-189">資料庫活動的短期突波可能會造成檢查點及合併作業落後，這會增加所需的資料和差異檔案組數。</span><span class="sxs-lookup"><span data-stu-id="3a363-189">Short-term surges in database activity may cause checkpoint and merge operations lag, which will increase the number of required data and delta file pairs.</span></span> <span data-ttu-id="3a363-190">為了容納資料庫活動的短期突波尖峰，儲存體系統可以配置最多 8,000 個資料和差異檔案組，總儲存體大小高達 1TB。</span><span class="sxs-lookup"><span data-stu-id="3a363-190">To accommodate short-term surges spikes in database activity, the storage system can allocate up to 8,000 data and delta file pairs up to a total of 1TB of storage.</span></span> <span data-ttu-id="3a363-191">達到該限制時，資料庫上將不允許新交易，直到檢查點作業趕上為止。</span><span class="sxs-lookup"><span data-stu-id="3a363-191">When that limit is reached, there will be no new transactions allowed on the database until checkpoint operations catch up.</span></span> <span data-ttu-id="3a363-192">如果持久的資料表大小在記憶體中長時間超過 250GB，就有可能會達到 8,000 個檔案組的限制。</span><span class="sxs-lookup"><span data-stu-id="3a363-192">If the size of durable tables in memory exceeds 250GB for long periods of time, there is a chance of reaching the 8,000 file pair limit.</span></span>

 <span data-ttu-id="3a363-193">合併作業將根據內部定義的合併原則，接受一個或多個相鄰且已關閉的 CFP (稱為合併來源) 當做輸入，並且產生單一 CFP 結果，稱為合併目標。</span><span class="sxs-lookup"><span data-stu-id="3a363-193">The merge operation takes as input one or more adjacent closed CFPs (called merge source) based on an internally defined merge policy, and produces one resultant CFP, called the merge target.</span></span> <span data-ttu-id="3a363-194">來源 CFP 的每個差異檔案中的項目用於篩選對應資料檔案中的資料列，以移除不再需要的資料列。</span><span class="sxs-lookup"><span data-stu-id="3a363-194">The entries in each delta file of the source CFPs are used to filter rows from the corresponding data file to remove the data rows that are not needed.</span></span> <span data-ttu-id="3a363-195">來源 CFP 中剩餘的資料列則會合併成單一目標 CFP。</span><span class="sxs-lookup"><span data-stu-id="3a363-195">The remaining rows in the source CFPs are consolidated into one target CFP.</span></span> <span data-ttu-id="3a363-196">在合併完成後，產生的合併目標 CFP 將取代來源 CFP (合併來源)。</span><span class="sxs-lookup"><span data-stu-id="3a363-196">After the merge is complete, the resultant merge-target CFP replaces the source CFPs (merge sources).</span></span> <span data-ttu-id="3a363-197">合併來源 CFP 會歷經一個過渡階段後才從儲存體移除。</span><span class="sxs-lookup"><span data-stu-id="3a363-197">The merge-source CFPs go through a transition phase before they are removed from storage.</span></span>

 <span data-ttu-id="3a363-198">在底下的範例中，記憶體最佳化資料表檔案群組在時間戳記 500 有四個資料檔案和差異檔案組包含了得自先前交易的資料。</span><span class="sxs-lookup"><span data-stu-id="3a363-198">In the example below, the memory-optimized table file group has four data and delta file pairs at timestamp 500 containing data from previous transactions.</span></span> <span data-ttu-id="3a363-199">例如，第一個資料檔案中的資料列對應到時間戳記大於 100 且小於或等於 200 (或者以 (100, 200] 表示) 的交易。</span><span class="sxs-lookup"><span data-stu-id="3a363-199">For example, the rows in the first data file correspond to transactions with timestamp greater than 100 and less than or equal to 200; alternatively represented as (100, 200].</span></span> <span data-ttu-id="3a363-200">在考量到資料列標記為已刪除的情況下，第二和第三個資料檔案會顯示為低於 50% 已滿。</span><span class="sxs-lookup"><span data-stu-id="3a363-200">The second and third data files are shown to be less than 50 percent full after accounting for the rows marked as deleted.</span></span> <span data-ttu-id="3a363-201">合併作業會結合這兩個 CFP 並且建立新的 CFP，其包含了時間戳記大於 200 且小於或等於 400 的交易，也就是這兩個 CFP 合併的範圍。</span><span class="sxs-lookup"><span data-stu-id="3a363-201">The merge operation combines these two CFPs and creates a new CFP containing transactions with timestamp greater than 200 and less than or equal to 400, which is the combined range of these two CFPs.</span></span> <span data-ttu-id="3a363-202">如您所見，另有一個 CFP 的範圍為 (500, 600] 以及在交易範圍 (200, 400] 的非空白差異檔案，表示合併作業可與交易活動同時完成，包括刪除來源 CFP 中的更多資料列。</span><span class="sxs-lookup"><span data-stu-id="3a363-202">You see another CFP with range (500, 600] and non-empty delta file for transaction range (200, 400] shows that merge operation can be done concurrently with transactional activity including deleting more rows from the source CFPs.</span></span>

 <span data-ttu-id="3a363-203">![圖表顯示記憶體最佳化資料表檔案群組](../../database-engine/media/storagediagram-hekaton.png "圖表顯示記憶體最佳化資料表檔案群組")</span><span class="sxs-lookup"><span data-stu-id="3a363-203">![Diagram shows memory optimized table file group](../../database-engine/media/storagediagram-hekaton.png "Diagram shows memory optimized table file group")</span></span>

 <span data-ttu-id="3a363-204">背景執行緒會使用合併原則評估所有已關閉的 CFP，然後起始一項或多項對合格 CFP 的合併要求。</span><span class="sxs-lookup"><span data-stu-id="3a363-204">A background thread evaluates all closed CFPs using a merge policy and then initiates one or more merge requests for the qualifying CFPs.</span></span> <span data-ttu-id="3a363-205">這些合併要求將由離線檢查點執行緒來處理。</span><span class="sxs-lookup"><span data-stu-id="3a363-205">These merge requests are processed by the offline checkpoint thread.</span></span> <span data-ttu-id="3a363-206">系統會定期評估合併原則，以及在檢查點關閉時進行評估。</span><span class="sxs-lookup"><span data-stu-id="3a363-206">The evaluation of merge policy is done periodically and also when a checkpoint is closed.</span></span>

### <a name="sssql14-merge-policy"></a>[!INCLUDE[ssSQL14](../../../includes/sssql14-md.md)] <span data-ttu-id="3a363-207">合併原則</span><span class="sxs-lookup"><span data-stu-id="3a363-207">Merge Policy</span></span>
 [!INCLUDE[ssSQL14](../../../includes/sssql14-md.md)] <span data-ttu-id="3a363-208">實作以下合併原則：</span><span class="sxs-lookup"><span data-stu-id="3a363-208">implements the following merge policy:</span></span>

-   <span data-ttu-id="3a363-209">在考量到已刪除的資料列之後，如果可以合併兩個或多個連續的 CFP，使其產生的資料列數能夠納入 1 個理想大小的 CFP，就會排程進行合併。</span><span class="sxs-lookup"><span data-stu-id="3a363-209">A merge is scheduled if 2 or more consecutive CFPs can be consolidated, after accounting for deleted rows, such that the resultant rows can fit into 1 CFP of ideal size.</span></span> <span data-ttu-id="3a363-210">CFP 的理想大小會以下列方式決定：</span><span class="sxs-lookup"><span data-stu-id="3a363-210">The ideal size of CFP is determined as follows:</span></span>

    -   <span data-ttu-id="3a363-211">如果電腦的記憶體小於或等於 16GB，則資料檔案是 16MB，而且差異檔案是 1MB。</span><span class="sxs-lookup"><span data-stu-id="3a363-211">If a computer has less than or equal to 16GB of memory, the data file is 16MB and delta file is 1MB.</span></span>

    -   <span data-ttu-id="3a363-212">如果電腦的記憶體大於 16GB，則資料檔案是 128MB，而且差異檔案是 16MB。</span><span class="sxs-lookup"><span data-stu-id="3a363-212">If a computer has greater than 16GB of memory, the data file is 128MB and delta file is 16MB.</span></span>

-   <span data-ttu-id="3a363-213">如果資料檔案超過 256 MB，而且一半以上的資料列已刪除，則單一 CFP 可以自行合併。</span><span class="sxs-lookup"><span data-stu-id="3a363-213">A single CFP can be self-merged if the data file exceeds 256 MB and more than half of the rows are deleted.</span></span> <span data-ttu-id="3a363-214">資料檔案可以超出 128MB，例如，單一交易或多個並行交易插入或更新大量資料，強制資料檔案超出其理想大小，因為交易無法跨越多個 CFP。</span><span class="sxs-lookup"><span data-stu-id="3a363-214">A data file can grow larger than 128MB if, for example, a single transaction or multiple concurrent transactions inserts or updates large amount of data, forcing the data file to grow beyond its ideal size because a transaction cannot span multiple CFPs.</span></span>

 <span data-ttu-id="3a363-215">以下幾個範例顯示根據合併原則將會合併的 CFP：</span><span class="sxs-lookup"><span data-stu-id="3a363-215">Here are some examples that show the CFPs that will be merged under the merge policy:</span></span>

|<span data-ttu-id="3a363-216">相鄰的 CFP 來源檔案 (% 已滿)</span><span class="sxs-lookup"><span data-stu-id="3a363-216">Adjacent CFPs Source Files (% full)</span></span>|<span data-ttu-id="3a363-217">合併選取</span><span class="sxs-lookup"><span data-stu-id="3a363-217">Merge Selection</span></span>|
|-------------------------------------------|---------------------|
|<span data-ttu-id="3a363-218">CFP0 (30%)、CFP1 (50%)、CFP2 (50%)、CFP3 (90%)</span><span class="sxs-lookup"><span data-stu-id="3a363-218">CFP0 (30%), CFP1 (50%), CFP2 (50%), CFP3 (90%)</span></span>|<span data-ttu-id="3a363-219">(CFP0、CFP1)</span><span class="sxs-lookup"><span data-stu-id="3a363-219">(CFP0, CFP1)</span></span><br /><br /> <span data-ttu-id="3a363-220">未選擇 CFP2 是因為此項目會使得產生的資料檔案超過理想大小的 100%。</span><span class="sxs-lookup"><span data-stu-id="3a363-220">CFP2 is not chosen as it will make resultant data file greater than 100% of the ideal size.</span></span>|
|<span data-ttu-id="3a363-221">CFP0 (30%)、CFP1 (20%)、CFP2 (50%)、CFP3 (10%)</span><span class="sxs-lookup"><span data-stu-id="3a363-221">CFP0 (30%), CFP1 (20%), CFP2 (50%), CFP3 (10%)</span></span>|<span data-ttu-id="3a363-222">(CFP0、CFP1、CFP2)。</span><span class="sxs-lookup"><span data-stu-id="3a363-222">(CFP0, CFP1, CFP2).</span></span> <span data-ttu-id="3a363-223">從左邊開始選擇檔案。</span><span class="sxs-lookup"><span data-stu-id="3a363-223">Files are chosen starting from left.</span></span><br /><br /> <span data-ttu-id="3a363-224">未選擇 CTP3 是因為此項目會使得產生的資料檔案超過理想大小的 100%。</span><span class="sxs-lookup"><span data-stu-id="3a363-224">CTP3 is not chosen as it will make resultant data file greater than 100% of the ideal size.</span></span>|
|<span data-ttu-id="3a363-225">CFP0 (80%)、CFP1 (30%)、CFP2 (10%)、CFP3 (40%)</span><span class="sxs-lookup"><span data-stu-id="3a363-225">CFP0 (80%), CFP1 (30%), CFP2 (10%), CFP3 (40%)</span></span>|<span data-ttu-id="3a363-226">(CFP1、CFP2、CFP3)。</span><span class="sxs-lookup"><span data-stu-id="3a363-226">(CFP1, CFP2, CFP3).</span></span> <span data-ttu-id="3a363-227">從左邊開始選擇檔案。</span><span class="sxs-lookup"><span data-stu-id="3a363-227">Files are chosen starting from left.</span></span><br /><br /> <span data-ttu-id="3a363-228">略過 CFP0 是因為此項目若與 CFP1 合併，產生的資料檔案將會超過理想大小的 100%。</span><span class="sxs-lookup"><span data-stu-id="3a363-228">CFP0 is skipped because if combined with CFP1, the resultant data file will be greater than 100% of the ideal size.</span></span>|

 <span data-ttu-id="3a363-229">並非所有餘留可用空間的 CFP 都有資格進行合併。</span><span class="sxs-lookup"><span data-stu-id="3a363-229">Not all CFPs with available space qualify for merge.</span></span> <span data-ttu-id="3a363-230">例如，若兩個相鄰的 CFP 都是 60% 已滿，就沒有資格進行合併，而且這些 CFP 各自仍將有 40% 未使用的儲存空間。</span><span class="sxs-lookup"><span data-stu-id="3a363-230">For example, if two adjacent CFPs are 60% full, they will not qualify for merge and each of these CFPs will have 40% storage unused.</span></span> <span data-ttu-id="3a363-231">最糟的情況是所有 CFP 皆為 50% 已滿，儲存空間利用率只達 50%。</span><span class="sxs-lookup"><span data-stu-id="3a363-231">In the worst case, all CFPs will be 50% full, a storage utilization of only 50%.</span></span> <span data-ttu-id="3a363-232">已刪除的資料列可能由於 CFP 沒有資格進行合併而仍存在於儲存體中，但是記憶體內部記憶體回收可能已從記憶體移除已刪除的資料列。</span><span class="sxs-lookup"><span data-stu-id="3a363-232">While the deleted rows may exist in storage because the CFPs don't qualify for merge, the deleted rows may have already been removed from memory by in-memory garbage collection.</span></span> <span data-ttu-id="3a363-233">儲存體和記憶體的管理與記憶體回收無關。</span><span class="sxs-lookup"><span data-stu-id="3a363-233">The management of storage and the memory is independent from garbage collection.</span></span> <span data-ttu-id="3a363-234">使用中 CFP 所佔的儲存空間 (未必所有 CFP 一概更新) 最多可達記憶體中持久性資料表大小的 2 倍。</span><span class="sxs-lookup"><span data-stu-id="3a363-234">Storage taken by active CFPs (not all CFPs are being updated) can be up to 2 times larger than the size of durable tables in memory.</span></span>

 <span data-ttu-id="3a363-235">如有需要，可以藉由呼叫[sys.databases sp_xtp_merge_checkpoint_files &#40;transact-sql&#41;](/sql/relational-databases/system-stored-procedures/sys-sp-xtp-merge-checkpoint-files-transact-sql)明確地執行手動合併。</span><span class="sxs-lookup"><span data-stu-id="3a363-235">If needed, a manual merge can be explicitly performed by calling [sys.sp_xtp_merge_checkpoint_files &#40;Transact-SQL&#41;](/sql/relational-databases/system-stored-procedures/sys-sp-xtp-merge-checkpoint-files-transact-sql).</span></span>

### <a name="life-cycle-of-a-cfp"></a><span data-ttu-id="3a363-236">CFP 的生命週期</span><span class="sxs-lookup"><span data-stu-id="3a363-236">Life Cycle of a CFP</span></span>
 <span data-ttu-id="3a363-237">CPF 解除配置之前會歷經幾個過渡狀態。</span><span class="sxs-lookup"><span data-stu-id="3a363-237">CPFs transition through several states before they can be deallocated.</span></span> <span data-ttu-id="3a363-238">在任何給定的時間，CFP 都會處於以下其中一個階段：已預先建立、建構中、使用中、合併目標、已合併來源、備份/高可用性所需、正在轉換為標記和標記。</span><span class="sxs-lookup"><span data-stu-id="3a363-238">At any given time, the CFPs are in one of the following phases: PRECREATED, UNDER CONSTRUCTION, ACTIVE, MERGE TARGET, MERGED SOURCE, REQUIRED FOR BACKUP/HA, IN TRANSITION TO TOMBSTONE, and TOMBSTONE.</span></span> <span data-ttu-id="3a363-239">如需這些階段的說明，請參閱 [sys.dm_db_xtp_checkpoint_files &#40;Transact-SQL&#41;](/sql/relational-databases/system-dynamic-management-views/sys-dm-db-xtp-checkpoint-files-transact-sql)。</span><span class="sxs-lookup"><span data-stu-id="3a363-239">For a description of these phases, see [sys.dm_db_xtp_checkpoint_files &#40;Transact-SQL&#41;](/sql/relational-databases/system-dynamic-management-views/sys-dm-db-xtp-checkpoint-files-transact-sql).</span></span>

 <span data-ttu-id="3a363-240">在考量到 CFP 在各個不同階段所佔的儲存空間之後，持久的記憶體最佳化資料表所佔的整體儲存空間可能遠大於該資料表在記憶體中大小的 2 倍。</span><span class="sxs-lookup"><span data-stu-id="3a363-240">After accounting for the storage taken by CFPs in various states, the overall storage taken by durable memory-optimized tables can be much larger than 2 times the size of the tables in memory.</span></span> <span data-ttu-id="3a363-241">您可以查詢 DMV [sys. dm_db_xtp_checkpoint_files &#40;transact-sql&#41;](/sql/relational-databases/system-dynamic-management-views/sys-dm-db-xtp-checkpoint-files-transact-sql)來列出記憶體優化檔案群組中的所有 cfp，包括其階段。</span><span class="sxs-lookup"><span data-stu-id="3a363-241">The DMV [sys.dm_db_xtp_checkpoint_files &#40;Transact-SQL&#41;](/sql/relational-databases/system-dynamic-management-views/sys-dm-db-xtp-checkpoint-files-transact-sql) can be queried to list all the CFPs in the memory-optimized filegroup, including their phase.</span></span> <span data-ttu-id="3a363-242">將 CFP 從「合併來源」狀態轉換為「標記」狀態且最後為記憶體回收的程序，最多可能會使用五個檢查點，每個檢查點後面都接著交易記錄備份 (如果資料庫有設定完整或大量記錄復原模式)。</span><span class="sxs-lookup"><span data-stu-id="3a363-242">Transitioning CFPs from MERGE SOURCE state to TOMBSTONE and ultimately garbage collection can take up five checkpoints, with each checkpoint followed by a transaction log backup, if the database is configured for full or bulk-logged recovery model.</span></span>

 <span data-ttu-id="3a363-243">您可以手動強制檢查點過後即執行記錄備份以加速記憶體回收，但是這樣將會增加 5 個空的 CFP (5 組資料/差異檔案組，每個資料檔案的大小為 128MB)。</span><span class="sxs-lookup"><span data-stu-id="3a363-243">You can manually force the checkpoint followed by log backup to expedite the garbage collection but then this will add 5 empty CFPs (5 data/delta file pairs with data file of size 128MB each).</span></span> <span data-ttu-id="3a363-244">在實際狀況下，做為部分備份策略的自動檢查點和記錄備份，將能在這些階段中順利轉換 CFP，而不需要任何手動介入。</span><span class="sxs-lookup"><span data-stu-id="3a363-244">In production scenarios, the automatic checkpoints and log backups taken as part of backup strategy will seamlessly transition CFPs through these phases without requiring any manual intervention.</span></span> <span data-ttu-id="3a363-245">記憶體回收處理序造成的影響是，具有記憶體最佳化資料表的資料庫其儲存體大小可能高於在記憶體中的大小。</span><span class="sxs-lookup"><span data-stu-id="3a363-245">The impact of the garbage collection process is that databases with memory-optimized tables may have a larger storage size compared to its size in memory.</span></span> <span data-ttu-id="3a363-246">CFP 是記憶體中持久性記憶體最佳化資料表大小高達四倍的情形是可能發生的狀況。</span><span class="sxs-lookup"><span data-stu-id="3a363-246">It is not uncommon for CFPs to be up to four times the size of the durable memory-optimized tables in memory.</span></span>

## <a name="see-also"></a><span data-ttu-id="3a363-247">另請參閱</span><span class="sxs-lookup"><span data-stu-id="3a363-247">See Also</span></span>
 [<span data-ttu-id="3a363-248">建立及管理記憶體最佳化物件的儲存體</span><span class="sxs-lookup"><span data-stu-id="3a363-248">Creating and Managing Storage for Memory-Optimized Objects</span></span>](creating-and-managing-storage-for-memory-optimized-objects.md)


