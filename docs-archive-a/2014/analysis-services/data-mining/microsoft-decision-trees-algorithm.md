---
title: Microsoft 決策樹演算法 |Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- predictions [Analysis Services], discrete attributes
- predictions [Analysis Services], continuous attributes
- algorithms [data mining]
- discrete attributes [Analysis Services]
- classification algorithms [Analysis Services]
- discrete columns [Analysis Services]
- decision tree algorithms [Analysis Services]
- decision trees [Analysis Services]
- continuous columns
- regression algorithms [Analysis Services]
ms.assetid: 95ffe66f-c261-4dc5-ad57-14d2d73205ff
author: minewiskan
ms.author: owend
ms.openlocfilehash: 3c9a893a6f0cb02e5acd2e497e0b57c29d7ac2ca
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 08/04/2020
ms.locfileid: "87597440"
---
# <a name="microsoft-decision-trees-algorithm"></a><span data-ttu-id="21e25-102">Microsoft 決策樹演算法</span><span class="sxs-lookup"><span data-stu-id="21e25-102">Microsoft Decision Trees Algorithm</span></span>
  <span data-ttu-id="21e25-103">[!INCLUDE[msCoName](../../includes/msconame-md.md)]決策樹演算法是提供的分類和回歸演算法，可 [!INCLUDE[msCoName](../../includes/msconame-md.md)] [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] 用於離散和連續屬性的預測模型。</span><span class="sxs-lookup"><span data-stu-id="21e25-103">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm is a classification and regression algorithm provided by [!INCLUDE[msCoName](../../includes/msconame-md.md)] [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] for use in predictive modeling of both discrete and continuous attributes.</span></span>

 <span data-ttu-id="21e25-104">針對分隔屬性，此演算法依據資料集內的輸入資料行之間的關聯性來產生預測。</span><span class="sxs-lookup"><span data-stu-id="21e25-104">For discrete attributes, the algorithm makes predictions based on the relationships between input columns in a dataset.</span></span> <span data-ttu-id="21e25-105">它會使用這些資料行的值 (稱為狀態) 來預測您指定為可預測之資料行的狀態。</span><span class="sxs-lookup"><span data-stu-id="21e25-105">It uses the values, known as states, of those columns to predict the states of a column that you designate as predictable.</span></span> <span data-ttu-id="21e25-106">尤其，此演算法會識別與可預測資料行相互關聯的輸入資料行。</span><span class="sxs-lookup"><span data-stu-id="21e25-106">Specifically, the algorithm identifies the input columns that are correlated with the predictable column.</span></span> <span data-ttu-id="21e25-107">例如，在預測哪些客戶可能購買腳踏車的狀況中，如果 10 個年輕客戶當中有 9 個購買腳踏車，但 10 個年紀較大的客戶當中只有 2 個人這麼做，則演算法會推斷年齡是腳踏車購買的理想預測器。</span><span class="sxs-lookup"><span data-stu-id="21e25-107">For example, in a scenario to predict which customers are likely to purchase a bicycle, if nine out of ten younger customers buy a bicycle, but only two out of ten older customers do so, the algorithm infers that age is a good predictor of bicycle purchase.</span></span> <span data-ttu-id="21e25-108">決策樹就是依據傾向於特定結果的趨勢來產生預測。</span><span class="sxs-lookup"><span data-stu-id="21e25-108">The decision tree makes predictions based on this tendency toward a particular outcome.</span></span>

 <span data-ttu-id="21e25-109">針對連續屬性，此演算法使用線性迴歸來決定決策樹分岔之處。</span><span class="sxs-lookup"><span data-stu-id="21e25-109">For continuous attributes, the algorithm uses linear regression to determine where a decision tree splits.</span></span>

 <span data-ttu-id="21e25-110">如果不止一個資料行設定為可預測，或輸入資料包含的巢狀資料表設定為可預測，則演算法會建立每一個可預測資料行的個別決策樹。</span><span class="sxs-lookup"><span data-stu-id="21e25-110">If more than one column is set to predictable, or if the input data contains a nested table that is set to predictable, the algorithm builds a separate decision tree for each predictable column</span></span>

## <a name="example"></a><span data-ttu-id="21e25-111">範例</span><span class="sxs-lookup"><span data-stu-id="21e25-111">Example</span></span>
 <span data-ttu-id="21e25-112">[!INCLUDE[ssSampleDBCoFull](../../includes/sssampledbcofull-md.md)] 公司的行銷部門想要識別舊客戶的特性，這些特性會指出那些客戶是否可能購買未來的產品。</span><span class="sxs-lookup"><span data-stu-id="21e25-112">The marketing department of the [!INCLUDE[ssSampleDBCoFull](../../includes/sssampledbcofull-md.md)] company wants to identify the characteristics of previous customers that might indicate whether those customers are likely to buy a product in the future.</span></span> <span data-ttu-id="21e25-113">[!INCLUDE[ssSampleDBnormal](../../includes/sssampledbnormal-md.md)] 資料庫會儲存描述舊客戶的人口統計資訊。</span><span class="sxs-lookup"><span data-stu-id="21e25-113">The [!INCLUDE[ssSampleDBnormal](../../includes/sssampledbnormal-md.md)] database stores demographic information that describes previous customers.</span></span> <span data-ttu-id="21e25-114">藉由使用 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 決策樹演算法來分析此資訊，行銷部門可以建立模型，依據關於特定客戶之已知資料行的狀態 (例如人口統計或過去購買模式) 來預測該客戶是否會購買產品。</span><span class="sxs-lookup"><span data-stu-id="21e25-114">By using the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm to analyze this information, the marketing department can build a model that predicts whether a particular customer will purchase products, based on the states of known columns about that customer, such as demographics or past buying patterns.</span></span>

## <a name="how-the-algorithm-works"></a><span data-ttu-id="21e25-115">演算法的運作方式</span><span class="sxs-lookup"><span data-stu-id="21e25-115">How the Algorithm Works</span></span>
 <span data-ttu-id="21e25-116">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 決策樹演算法會在樹狀結構中建立一系列分割，藉以建立資料採礦模型。</span><span class="sxs-lookup"><span data-stu-id="21e25-116">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm builds a data mining model by creating a series of splits in the tree.</span></span> <span data-ttu-id="21e25-117">然後，這些分割會表示成「節點」\*\*。</span><span class="sxs-lookup"><span data-stu-id="21e25-117">These splits are represented as *nodes*.</span></span> <span data-ttu-id="21e25-118">每次發現輸入資料行與可預測資料行有明顯地相互關聯時，此演算法就會在模型中加入一個節點。</span><span class="sxs-lookup"><span data-stu-id="21e25-118">The algorithm adds a node to the model every time that an input column is found to be significantly correlated with the predictable column.</span></span> <span data-ttu-id="21e25-119">演算法決定分岔的方式不同，視它預測連續資料行或分隔資料行而定。</span><span class="sxs-lookup"><span data-stu-id="21e25-119">The way that the algorithm determines a split is different depending on whether it is predicting a continuous column or a discrete column.</span></span>

 <span data-ttu-id="21e25-120">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 決策樹演算法會使用「特徵選取」\*\* 來引導選取最有用的屬性。</span><span class="sxs-lookup"><span data-stu-id="21e25-120">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm uses *feature selection* to guide the selection of the most useful attributes.</span></span> <span data-ttu-id="21e25-121">所有 [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] 資料採礦演算法都會使用特徵選取來改善效能和分析的品質。</span><span class="sxs-lookup"><span data-stu-id="21e25-121">Feature selection is used by all [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] data mining algorithms to improve performance and the quality of analysis.</span></span> <span data-ttu-id="21e25-122">若要防止不重要的屬性佔用處理器時間，特徵選取就很重要。</span><span class="sxs-lookup"><span data-stu-id="21e25-122">Feature selection is important to prevent unimportant attributes from using processor time.</span></span> <span data-ttu-id="21e25-123">如果您在設計資料採礦模型時使用過多輸入或可預測的屬性，此模型可能會需要很長的時間才能處理完成，甚至用完記憶體。</span><span class="sxs-lookup"><span data-stu-id="21e25-123">If you use too many input or predictable attributes when you design a data mining model, the model can take a very long time to process, or even run out of memory.</span></span> <span data-ttu-id="21e25-124">用來判斷是否要分割樹狀結構的方法包括 *entropy* 和 Bayesian 網路的業界標準。\*\*</span><span class="sxs-lookup"><span data-stu-id="21e25-124">Methods used to determine whether to split the tree include industry-standard metrics for *entropy* and Bayesian networks *.*</span></span> <span data-ttu-id="21e25-125">如需用來選取有意義屬性，然後針對這些屬性計分並排名之方法的詳細資訊，請參閱[特徵選取 &#40;資料採礦&#41;](feature-selection-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="21e25-125">For more information about the methods used to select meaningful attributes and then score and rank the attributes, see [Feature Selection &#40;Data Mining&#41;](feature-selection-data-mining.md).</span></span>

 <span data-ttu-id="21e25-126">資料採礦模型中常見的問題是，模型變得太敏感，而不是定型資料中的小差異，在此情況下，它會被視為*過度*調整或*過度定型*。</span><span class="sxs-lookup"><span data-stu-id="21e25-126">A common problem in data mining models is that the model becomes too sensitive to small differences in the training data, in which case it said to be *over-fitted* or *over-trained*.</span></span> <span data-ttu-id="21e25-127">過度調整的模型無法一般化成為其他資料集。</span><span class="sxs-lookup"><span data-stu-id="21e25-127">An overfitted model cannot be generalized to other data sets.</span></span> <span data-ttu-id="21e25-128">為了避免過度調整任何特定資料集， [!INCLUDE[msCoName](../../includes/msconame-md.md)] 決策樹演算法會使用控制樹狀目錄成長的技術。</span><span class="sxs-lookup"><span data-stu-id="21e25-128">To avoid overfitting on any particular set of data, the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm uses techniques for controlling the growth of the tree.</span></span> <span data-ttu-id="21e25-129">如需 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 決策樹演算法如何運作的更深入說明，請參閱 [Microsoft 決策樹演算法技術參考](microsoft-decision-trees-algorithm-technical-reference.md)。</span><span class="sxs-lookup"><span data-stu-id="21e25-129">For a more in-depth explanation of how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works, see [Microsoft Decision Trees Algorithm Technical Reference](microsoft-decision-trees-algorithm-technical-reference.md).</span></span>

### <a name="predicting-discrete-columns"></a><span data-ttu-id="21e25-130">預測分隔資料行</span><span class="sxs-lookup"><span data-stu-id="21e25-130">Predicting Discrete Columns</span></span>
 <span data-ttu-id="21e25-131">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 決策樹演算法為分隔可預測資料行建立樹狀結構的方式，可使用長條圖來示範。</span><span class="sxs-lookup"><span data-stu-id="21e25-131">The way that the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm builds a tree for a discrete predictable column can be demonstrated by using a histogram.</span></span> <span data-ttu-id="21e25-132">下列圖表顯示一個長條圖，它繪製出可預測資料行 Bike Buyers 對照輸入資料行 Age。</span><span class="sxs-lookup"><span data-stu-id="21e25-132">The following diagram shows a histogram that plots a predictable column, Bike Buyers, against an input column, Age.</span></span> <span data-ttu-id="21e25-133">長條圖顯示某人的年齡可協助區分此人是否會購買腳踏車。</span><span class="sxs-lookup"><span data-stu-id="21e25-133">The histogram shows that the age of a person helps distinguish whether that person will purchase a bicycle.</span></span>

 <span data-ttu-id="21e25-134">![來自 Microsoft 決策樹演算法的長條圖](../media/dt-histogram.gif "來自 Microsoft 決策樹演算法的長條圖")</span><span class="sxs-lookup"><span data-stu-id="21e25-134">![Histogram from Microsoft Decision Trees algorithm](../media/dt-histogram.gif "Histogram from Microsoft Decision Trees algorithm")</span></span>

 <span data-ttu-id="21e25-135">圖表中所顯示的相互關聯會導致 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 決策樹演算法在模型中建立新節點。</span><span class="sxs-lookup"><span data-stu-id="21e25-135">The correlation that is shown in the diagram would cause the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm to create a new node in the model.</span></span>

 <span data-ttu-id="21e25-136">![決策樹節點](../media/dt-tree.gif "決策樹節點")</span><span class="sxs-lookup"><span data-stu-id="21e25-136">![Decision tree node](../media/dt-tree.gif "Decision tree node")</span></span>

 <span data-ttu-id="21e25-137">當演算法在模型中加入新節點時，就會形成樹狀結構。</span><span class="sxs-lookup"><span data-stu-id="21e25-137">As the algorithm adds new nodes to a model, a tree structure is formed.</span></span> <span data-ttu-id="21e25-138">樹狀的最上層節點描述客戶整體母體擴展之可預測資料行的細分。</span><span class="sxs-lookup"><span data-stu-id="21e25-138">The top node of the tree describes the breakdown of the predictable column for the overall population of customers.</span></span> <span data-ttu-id="21e25-139">當模型繼續成長時，演算法會考量所有資料行。</span><span class="sxs-lookup"><span data-stu-id="21e25-139">As the model continues to grow, the algorithm considers all columns.</span></span>

### <a name="predicting-continuous-columns"></a><span data-ttu-id="21e25-140">預測連續資料行</span><span class="sxs-lookup"><span data-stu-id="21e25-140">Predicting Continuous Columns</span></span>
 <span data-ttu-id="21e25-141">當 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 決策樹演算法依據連續可預測資料行建立樹狀結構時，每一個節點會包含一個迴歸公式。</span><span class="sxs-lookup"><span data-stu-id="21e25-141">When the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm builds a tree based on a continuous predictable column, each node contains a regression formula.</span></span> <span data-ttu-id="21e25-142">分岔會出現在迴歸公式中的非線性點上。</span><span class="sxs-lookup"><span data-stu-id="21e25-142">A split occurs at a point of non-linearity in the regression formula.</span></span> <span data-ttu-id="21e25-143">例如，請看下列圖表。</span><span class="sxs-lookup"><span data-stu-id="21e25-143">For example, consider the following diagram.</span></span>

 <span data-ttu-id="21e25-144">![顯示非線性的多條迴歸線](../media/regression-tree1.gif "顯示非線性的多條迴歸線")</span><span class="sxs-lookup"><span data-stu-id="21e25-144">![Multiple regression lines showing non-linearity](../media/regression-tree1.gif "Multiple regression lines showing non-linearity")</span></span>

 <span data-ttu-id="21e25-145">圖表包含可使用單線或使用兩條連接線建立模型的資料。</span><span class="sxs-lookup"><span data-stu-id="21e25-145">The diagram contains data that can be modeled either by using a single line or by using two connected lines.</span></span> <span data-ttu-id="21e25-146">不過，用單線來表示資料，效果較差。</span><span class="sxs-lookup"><span data-stu-id="21e25-146">However, a single line would do a poor job of representing the data.</span></span> <span data-ttu-id="21e25-147">相對地，如果您使用雙線，則模型更能做好模擬資料的作業。</span><span class="sxs-lookup"><span data-stu-id="21e25-147">Instead, if you use two lines, the model will do a much better job of approximating the data.</span></span> <span data-ttu-id="21e25-148">兩條線交叉的點就是非線性點，也是在決策樹模型中之節點會分岔的那個點。</span><span class="sxs-lookup"><span data-stu-id="21e25-148">The point where the two lines come together is the point of non-linearity, and is the point where a node in a decision tree model would split.</span></span> <span data-ttu-id="21e25-149">例如，對應至上面圖表中之非線性點的節點可由下列圖表來表示。</span><span class="sxs-lookup"><span data-stu-id="21e25-149">For example, the node that corresponds to the point of non-linearity in the previous graph could be represented by the following diagram.</span></span> <span data-ttu-id="21e25-150">兩個方程式代表兩條線的迴歸方程式。</span><span class="sxs-lookup"><span data-stu-id="21e25-150">The two equations represent the regression equations for the two lines.</span></span>

 <span data-ttu-id="21e25-151">![表示非線性點的方程式](../media/regression-tree2.gif "表示非線性點的方程式")</span><span class="sxs-lookup"><span data-stu-id="21e25-151">![Equation that represents a point of non-linearity](../media/regression-tree2.gif "Equation that represents a point of non-linearity")</span></span>

## <a name="data-required-for-decision-tree-models"></a><span data-ttu-id="21e25-152">決策樹模型所需的資料</span><span class="sxs-lookup"><span data-stu-id="21e25-152">Data Required for Decision Tree Models</span></span>
 <span data-ttu-id="21e25-153">當您準備資料以供決策樹模型使用時，應該要了解特定演算法的需求，包括所需的資料量及資料的使用方式等。</span><span class="sxs-lookup"><span data-stu-id="21e25-153">When you prepare data for use in a decision trees model, you should understand the requirements for the particular algorithm, including how much data is needed, and how the data is used.</span></span>

 <span data-ttu-id="21e25-154">決策樹模型的需求如下：</span><span class="sxs-lookup"><span data-stu-id="21e25-154">The requirements for a decision trees model are as follows:</span></span>

-   <span data-ttu-id="21e25-155">**單一索引鍵資料行** ：每個模型都必須包含一個能唯一識別每一筆記錄的數值或文字資料行。</span><span class="sxs-lookup"><span data-stu-id="21e25-155">**A single key column** Each model must contain one numeric or text column that uniquely identifies each record.</span></span> <span data-ttu-id="21e25-156">不允許複合的索引鍵。</span><span class="sxs-lookup"><span data-stu-id="21e25-156">Compound keys are not permitted.</span></span>

-   <span data-ttu-id="21e25-157">**可預測資料行** ：至少需要一個可預測資料行。</span><span class="sxs-lookup"><span data-stu-id="21e25-157">**A predictable column** Requires at least one predictable column.</span></span> <span data-ttu-id="21e25-158">您可以在模型中加入多個可預測的屬性，而且這些可預測的屬性可以屬於不同的類型：數值或離散。</span><span class="sxs-lookup"><span data-stu-id="21e25-158">You can include multiple predictable attributes in a model, and the predictable attributes can be of different types, either numeric or discrete.</span></span> <span data-ttu-id="21e25-159">不過，增加可預測屬性的數目可能會增加處理時間。</span><span class="sxs-lookup"><span data-stu-id="21e25-159">However, increasing the number of predictable attributes can increase processing time.</span></span>

-   <span data-ttu-id="21e25-160">**輸入資料行** ：需要可以是離散或連續的輸入資料行。</span><span class="sxs-lookup"><span data-stu-id="21e25-160">**Input columns** Requires input columns, which can be discrete or continuous.</span></span> <span data-ttu-id="21e25-161">增加輸入屬性的數目會影響處理時間。</span><span class="sxs-lookup"><span data-stu-id="21e25-161">Increasing the number of input attributes affects processing time.</span></span>

 <span data-ttu-id="21e25-162">如需決策樹模型所支援之內容類型和資料類型的詳細資訊，請參閱 [Microsoft 決策樹演算法技術參考](microsoft-decision-trees-algorithm-technical-reference.md)的＜需求＞一節。</span><span class="sxs-lookup"><span data-stu-id="21e25-162">For more detailed information about the content types and data types supported for decision tree models, see the Requirements section of [Microsoft Decision Trees Algorithm Technical Reference](microsoft-decision-trees-algorithm-technical-reference.md).</span></span>

## <a name="viewing-a-decision-trees-model"></a><span data-ttu-id="21e25-163">檢視決策樹模型</span><span class="sxs-lookup"><span data-stu-id="21e25-163">Viewing a Decision Trees Model</span></span>
 <span data-ttu-id="21e25-164">若要瀏覽此模型，您可以使用 [Microsoft 樹狀檢視器]\*\*\*\*。</span><span class="sxs-lookup"><span data-stu-id="21e25-164">To explore the model, you can use the **Microsoft Tree Viewer**.</span></span> <span data-ttu-id="21e25-165">如果模型產生了多個樹狀目錄，您就可以選取一個樹狀目錄，然後此檢視器會顯示這些案例如何針對每個可預測屬性分類的細目。</span><span class="sxs-lookup"><span data-stu-id="21e25-165">If your model generates multiple trees, you can select a tree and the viewer shows you a breakdown of how the cases are categorized for each predictable attribute.</span></span> <span data-ttu-id="21e25-166">您也可以使用相依性網路檢視器來檢視樹狀目錄的互動。</span><span class="sxs-lookup"><span data-stu-id="21e25-166">You can also view the interaction of the trees by using the dependency network viewer.</span></span> <span data-ttu-id="21e25-167">如需詳細資訊，請參閱 [使用 Microsoft 樹狀檢視器瀏覽模型](browse-a-model-using-the-microsoft-tree-viewer.md)。</span><span class="sxs-lookup"><span data-stu-id="21e25-167">For more information, see [Browse a Model Using the Microsoft Tree Viewer](browse-a-model-using-the-microsoft-tree-viewer.md).</span></span>

 <span data-ttu-id="21e25-168">如果您想要了解樹狀結構中任何分支或節點的詳細資料，也可以使用 [Microsoft 一般內容樹狀檢視器](browse-a-model-using-the-microsoft-generic-content-tree-viewer.md)來瀏覽此模型。</span><span class="sxs-lookup"><span data-stu-id="21e25-168">If you want to know more detail about any branch or node in the tree, you can also browse the model by using the [Microsoft Generic Content Tree Viewer](browse-a-model-using-the-microsoft-generic-content-tree-viewer.md).</span></span> <span data-ttu-id="21e25-169">針對此模型所儲存的內容包括每個節點中所有值的分佈、樹狀目錄之每個層級的機率，以及其連續屬性的迴歸公式。</span><span class="sxs-lookup"><span data-stu-id="21e25-169">The content stored for the model includes the distribution for all values in each node, probabilities at each level of the tree, and regression formulas for continuous attributes.</span></span> <span data-ttu-id="21e25-170">如需詳細資訊，請參閱 [決策樹模型的採礦模型內容 &#40;Analysis Services - 資料採礦&#41;](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="21e25-170">For more information, see [Mining Model Content for Decision Tree Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md).</span></span>

## <a name="creating-predictions"></a><span data-ttu-id="21e25-171">建立預測</span><span class="sxs-lookup"><span data-stu-id="21e25-171">Creating Predictions</span></span>
 <span data-ttu-id="21e25-172">在此模型已處理之後，結果會儲存成一組模式和統計資料，供您瀏覽關聯性或進行預測。</span><span class="sxs-lookup"><span data-stu-id="21e25-172">After the model has been processed, the results are stored as a set of patterns and statistics, which you can use to explore relationships or make predictions.</span></span>

 <span data-ttu-id="21e25-173">如需要搭配決策樹模型使用之查詢的範例，請參閱 [決策樹模型查詢範例](decision-trees-model-query-examples.md)。</span><span class="sxs-lookup"><span data-stu-id="21e25-173">For examples of queries to use with a decision trees model, see [Decision Trees Model Query Examples](decision-trees-model-query-examples.md).</span></span>

 <span data-ttu-id="21e25-174">如需如何針對採礦模型建立查詢的一般資訊，請參閱 [資料採礦查詢](data-mining-queries.md)。</span><span class="sxs-lookup"><span data-stu-id="21e25-174">For general information about how to create queries against mining models, see [Data Mining Queries](data-mining-queries.md).</span></span>

## <a name="remarks"></a><span data-ttu-id="21e25-175">備註</span><span class="sxs-lookup"><span data-stu-id="21e25-175">Remarks</span></span>

-   <span data-ttu-id="21e25-176">支援使用預測模型標記語言 (PMML) 來建立採礦模型。</span><span class="sxs-lookup"><span data-stu-id="21e25-176">Supports the use of Predictive Model Markup Language (PMML) to create mining models.</span></span>

-   <span data-ttu-id="21e25-177">支援鑽研。</span><span class="sxs-lookup"><span data-stu-id="21e25-177">Supports drillthrough.</span></span>

-   <span data-ttu-id="21e25-178">支援 OLAP 採礦模型的使用和資料採礦維度的建立。</span><span class="sxs-lookup"><span data-stu-id="21e25-178">Supports the use of OLAP mining models and the creation of data mining dimensions.</span></span>

## <a name="see-also"></a><span data-ttu-id="21e25-179">另請參閱</span><span class="sxs-lookup"><span data-stu-id="21e25-179">See Also</span></span>
 <span data-ttu-id="21e25-180">[資料採礦演算法 &#40;Analysis Services 資料採礦&#41;](data-mining-algorithms-analysis-services-data-mining.md) [Microsoft 決策樹演算法技術參考](microsoft-decision-trees-algorithm-technical-reference.md)[決策樹模型查詢範例](decision-trees-model-query-examples.md)[決策樹模型的採礦模型內容 &#40;Analysis Services-資料採礦&#41;](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)</span><span class="sxs-lookup"><span data-stu-id="21e25-180">[Data Mining Algorithms &#40;Analysis Services - Data Mining&#41;](data-mining-algorithms-analysis-services-data-mining.md) [Microsoft Decision Trees Algorithm Technical Reference](microsoft-decision-trees-algorithm-technical-reference.md) [Decision Trees Model Query Examples](decision-trees-model-query-examples.md) [Mining Model Content for Decision Tree Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)</span></span>


