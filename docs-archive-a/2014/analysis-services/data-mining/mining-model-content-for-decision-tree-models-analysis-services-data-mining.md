---
title: 決策樹模型 (Analysis Services 資料採礦) 的採礦模型內容 |Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- mining model content, decision tree models
- decision tree algorithms [Analysis Services]
- decision trees [Analysis Services]
ms.assetid: ac358399-10f8-4238-be32-a914a2e49048
author: minewiskan
ms.author: owend
ms.openlocfilehash: bd7c11219bd4807d019053e4100721e8cd6d658c
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 08/04/2020
ms.locfileid: "87594826"
---
# <a name="mining-model-content-for-decision-tree-models-analysis-services---data-mining"></a><span data-ttu-id="c653a-102">Mining Model Content for Decision Tree Models (Analysis Services - Data Mining)</span><span class="sxs-lookup"><span data-stu-id="c653a-102">Mining Model Content for Decision Tree Models (Analysis Services - Data Mining)</span></span>
  <span data-ttu-id="c653a-103">本主題描述使用 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 決策樹演算法的模型專用的採礦模型內容。</span><span class="sxs-lookup"><span data-stu-id="c653a-103">This topic describes mining model content that is specific to models that use the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm.</span></span> <span data-ttu-id="c653a-104">如需適用於所有模型類型的一般採礦模型內容說明，請參閱 [採礦模型內容 &#40;Analysis Services - 資料採礦&#41;](mining-model-content-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="c653a-104">For a general explanation of mining model content for all model types, see [Mining Model Content &#40;Analysis Services - Data Mining&#41;](mining-model-content-analysis-services-data-mining.md).</span></span> <span data-ttu-id="c653a-105">請務必記住，Microsoft 決策樹演算法是一種混合式演算法，可以建立功能非常不同的模型：決策樹可以代表關聯、規則，甚至線性迴歸。</span><span class="sxs-lookup"><span data-stu-id="c653a-105">It is important to remember that The Microsoft Decision Trees algorithm is a hybrid algorithm that can create models with very different functions: a decision tree can represent associations, rules, or even linear regression.</span></span> <span data-ttu-id="c653a-106">樹狀結構基本上相同，但是您解譯資訊的方式將取決於建立模型的目的。</span><span class="sxs-lookup"><span data-stu-id="c653a-106">The structure of the tree is essentially the same, but how you interpret the information will depend on the purpose for which you created the model.</span></span>  
  
##  <a name="understanding-the-structure-of-a-decision-trees-model"></a><a name="bkmk_Top"></a><span data-ttu-id="c653a-107">瞭解決策樹模型的結構</span><span class="sxs-lookup"><span data-stu-id="c653a-107">Understanding the Structure of a Decision Trees Model</span></span>  
 <span data-ttu-id="c653a-108">決策樹模型擁有代表模型及其中繼資料的單一父節點。</span><span class="sxs-lookup"><span data-stu-id="c653a-108">A decision trees model has a single parent node that represents the model and its metadata.</span></span> <span data-ttu-id="c653a-109">父節點下為獨立的樹狀結構，代表您選取的可預測屬性。</span><span class="sxs-lookup"><span data-stu-id="c653a-109">Underneath the parent node are independent trees that represent the predictable attributes that you select.</span></span> <span data-ttu-id="c653a-110">例如，如果您設定決策樹模型來預測客戶是否會購買某樣東西，而且提供性別和收入的輸入，此模型就會建立購買屬性的單一樹狀結構，其中包含針對性別和收入相關條件分類的許多分支。</span><span class="sxs-lookup"><span data-stu-id="c653a-110">For example, if you set up your decision tree model to predict whether customers will purchase something, and provide inputs for gender and income, the model would create a single tree for the purchasing attribute, with many branches that divide on conditions related to gender and income.</span></span>  
  
 <span data-ttu-id="c653a-111">不過，如果您接著要加入個別的可預測屬性來參與顧客獎勵計畫，此演算法將會在父節點下建立兩個個別的樹狀結構。</span><span class="sxs-lookup"><span data-stu-id="c653a-111">However, if you then add a separate predictable attribute for participation in a customer rewards program, the algorithm will create two separate trees under the parent node.</span></span> <span data-ttu-id="c653a-112">其中一個樹狀結構包含購買的分析，而另一個樹狀結構則包含顧客獎勵計畫的分析。</span><span class="sxs-lookup"><span data-stu-id="c653a-112">One tree contains the analysis for purchasing, and another tree contains the analysis for the customer rewards program.</span></span>  <span data-ttu-id="c653a-113">如果您使用決策樹演算法來建立關聯模型，此演算法會為每個要進行預測的產品建立一個個別的樹狀結構，而且該樹狀結構會包含可選取之目標屬性的其他所有產品組合。</span><span class="sxs-lookup"><span data-stu-id="c653a-113">If you use the Decision Trees algorithm to create an association model, the algorithm creates a separate tree for each product that is being predicted, and the tree contains all the other product combinations that contribute towards selection of the target attribute.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="c653a-114">如果您的模型包含多個樹狀結構，可以在 **[Microsoft 樹狀檢視器]** 中，一次僅檢視一個樹狀結構。</span><span class="sxs-lookup"><span data-stu-id="c653a-114">If your model includes multiple trees, you can view only one tree at a time in the **Microsoft Tree Viewer**.</span></span> <span data-ttu-id="c653a-115">不過，在 **[一般內容樹狀檢視器]** 中，相同模型中的所有樹狀結構會同時顯示出來。</span><span class="sxs-lookup"><span data-stu-id="c653a-115">However, in the **Generic Content Tree Viewer** , all trees in the same model are displayed at the same time.</span></span>  
  
 <span data-ttu-id="c653a-116">![決策樹的模型內容結構](../media/modelcontentstructure-dt.gif "決策樹的模型內容結構")</span><span class="sxs-lookup"><span data-stu-id="c653a-116">![structure of model content for decision tree](../media/modelcontentstructure-dt.gif "structure of model content for decision tree")</span></span>  
  
 <span data-ttu-id="c653a-117">每個可預測屬性的樹狀結構所包含的資訊會描述您選擇的輸入資料行如何影響該特定可預測屬性和結果。</span><span class="sxs-lookup"><span data-stu-id="c653a-117">The tree for each predictable attribute contains information that describes how the input columns that you choose affect the outcome of that particular predictable attribute.</span></span> <span data-ttu-id="c653a-118">每個樹狀結構開頭都是一個包含可預測屬性的節點 (NODE_TYPE = 9)，後面接著代表輸入屬性的一連串節點 (NODE_TYPE = 10)。</span><span class="sxs-lookup"><span data-stu-id="c653a-118">Each tree is headed by a node (NODE_TYPE = 9) that contains the predictable attribute, followed by a series of nodes (NODE_TYPE = 10) that represent the input attributes.</span></span> <span data-ttu-id="c653a-119">屬性會對應到案例層級的資料行或巢狀資料表資料行的值，這通常是巢狀資料表之 `Key` 資料行中的值。</span><span class="sxs-lookup"><span data-stu-id="c653a-119">An attribute corresponds to either a case-level column or values of nested table columns, which are generally the values in the `Key` column of the nested table.</span></span>  
  
 <span data-ttu-id="c653a-120">內部和分葉節點代表分岔條件。</span><span class="sxs-lookup"><span data-stu-id="c653a-120">Interior and leaf nodes represent split conditions.</span></span> <span data-ttu-id="c653a-121">樹狀結構可以在相同的屬性上分岔多次。</span><span class="sxs-lookup"><span data-stu-id="c653a-121">A tree can split on the same attribute multiple times.</span></span> <span data-ttu-id="c653a-122">例如， **TM_DecisionTree** 模型可能會針對 [Yearly Income] 和 [Number of Children] 分割，然後針對樹狀結構下的 [Yearly Income] 再分割一次。</span><span class="sxs-lookup"><span data-stu-id="c653a-122">For example, the **TM_DecisionTree** model might split on [Yearly Income] and [Number of Children], and then split again on [Yearly Income] further down the tree.</span></span>  
  
 <span data-ttu-id="c653a-123">Microsoft 決策樹演算法也可以在所有或部分樹狀結構中包含線性迴歸。</span><span class="sxs-lookup"><span data-stu-id="c653a-123">The Microsoft Decision Trees algorithm can also contain linear regressions in all or part of the tree.</span></span> <span data-ttu-id="c653a-124">如果您製作模型的屬性是連續的數值資料類型，此模型可以在屬性之間的關聯性能夠以線性方式製作模型的任何位置，建立迴歸樹狀節點 (NODE_TYPE = 25)。</span><span class="sxs-lookup"><span data-stu-id="c653a-124">If the attribute that you are modeling is a continuous numeric data type, the model can create a regression tree node (NODE_TYPE = 25) wherever the relationship between the attributes can be modeled linearly.</span></span> <span data-ttu-id="c653a-125">在此情況下，節點包含迴歸公式。</span><span class="sxs-lookup"><span data-stu-id="c653a-125">In this case, the node contains a regression formula.</span></span>  
  
 <span data-ttu-id="c653a-126">不過，如果可預測的屬性擁有離散值，或者如果數值經過儲存或離散化，此模型永遠會建立分類樹狀結構 (NODE_TYPE =2)。</span><span class="sxs-lookup"><span data-stu-id="c653a-126">However, if the predictable attribute has discrete values, or if numeric values have been bucketed or discretized, the model always creates a classification tree (NODE_TYPE =2).</span></span> <span data-ttu-id="c653a-127">分類樹狀結構針對每個屬性值，可以擁有多個分支或內部樹狀節點 (NODE_TYPE =3)。</span><span class="sxs-lookup"><span data-stu-id="c653a-127">A classification tree can have multiple branches or interior tree nodes (NODE_TYPE =3) for each value of the attribute.</span></span> <span data-ttu-id="c653a-128">不過，不一定要在屬性的每個值上進行分岔。</span><span class="sxs-lookup"><span data-stu-id="c653a-128">However, the split is not necessarily on each value of the attribute.</span></span>  
  
 <span data-ttu-id="c653a-129">Microsoft 決策樹演算法不允許使用連續資料類型當做輸入，因此，如果任何資料行有連續數值資料類型，就會將這些值離散化。</span><span class="sxs-lookup"><span data-stu-id="c653a-129">The Microsoft Decision Trees algorithm does not allow continuous data types as inputs; therefore, if any columns have a continuous numeric data type, the values are discretized.</span></span> <span data-ttu-id="c653a-130">此演算法會在所有連續屬性的分岔點執行自己的離散化。</span><span class="sxs-lookup"><span data-stu-id="c653a-130">The algorithm performs its own discretization at the point of a split for all continuous attributes.</span></span>  
  
> [!NOTE]  
>  [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] <span data-ttu-id="c653a-131">會自動選擇儲存連續屬性的方法，不過，您可以控制如何將輸入中的連續值離散化，方法是，將採礦結構資料行的內容類型設定為 `Discretized`，然後設定 <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> 或 <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> 屬性。</span><span class="sxs-lookup"><span data-stu-id="c653a-131">automatically chooses a method for bucketing continuous attributes; however, you can control how continuous values in the inputs are discretized by setting the content type of the mining structure column to `Discretized` and then setting the <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> or <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> property.</span></span>  
  
##  <a name="model-content-for-a-decision-trees-model"></a><a name="bkmk_ModelContent"></a> <span data-ttu-id="c653a-132">決策樹模型的模型內容</span><span class="sxs-lookup"><span data-stu-id="c653a-132">Model Content for a Decision Trees Model</span></span>  
 <span data-ttu-id="c653a-133">本節僅針對採礦模型內容中與決策樹模型具有特定相關的資料行，提供詳細資料和範例。</span><span class="sxs-lookup"><span data-stu-id="c653a-133">This section provides details and examples only for those columns in the mining model content that have particular relevance for decision trees models.</span></span> <span data-ttu-id="c653a-134">如需結構描述資料列集中一般用途資料行的資訊，以及採礦模型術語的說明，請參閱 [採礦模型內容 &#40;Analysis Services - 資料採礦&#41;](mining-model-content-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="c653a-134">For information about general-purpose columns in the schema rowset, and explanations of mining model terminology, see [Mining Model Content &#40;Analysis Services - Data Mining&#41;](mining-model-content-analysis-services-data-mining.md).</span></span>  
  
 <span data-ttu-id="c653a-135">MODEL_CATALOG</span><span class="sxs-lookup"><span data-stu-id="c653a-135">MODEL_CATALOG</span></span>  
 <span data-ttu-id="c653a-136">模型儲存位置所在資料庫的名稱。</span><span class="sxs-lookup"><span data-stu-id="c653a-136">Name of the database where the model is stored.</span></span>  
  
 <span data-ttu-id="c653a-137">MODEL_NAME</span><span class="sxs-lookup"><span data-stu-id="c653a-137">MODEL_NAME</span></span>  
 <span data-ttu-id="c653a-138">模型的名稱。</span><span class="sxs-lookup"><span data-stu-id="c653a-138">Name of the model.</span></span>  
  
 <span data-ttu-id="c653a-139">ATTRIBUTE_NAME</span><span class="sxs-lookup"><span data-stu-id="c653a-139">ATTRIBUTE_NAME</span></span>  
 <span data-ttu-id="c653a-140">對應至這個節點之屬性的名稱。</span><span class="sxs-lookup"><span data-stu-id="c653a-140">Name of the attribute that corresponds to this node.</span></span>  
  
 <span data-ttu-id="c653a-141">NODE_NAME</span><span class="sxs-lookup"><span data-stu-id="c653a-141">NODE_NAME</span></span>  
 <span data-ttu-id="c653a-142">永遠與 NODE_UNIQUE_NAME 相同。</span><span class="sxs-lookup"><span data-stu-id="c653a-142">Always same as NODE_UNIQUE_NAME.</span></span>  
  
 <span data-ttu-id="c653a-143">NODE_UNIQUE_NAME</span><span class="sxs-lookup"><span data-stu-id="c653a-143">NODE_UNIQUE_NAME</span></span>  
 <span data-ttu-id="c653a-144">節點在模型內的唯一識別項。</span><span class="sxs-lookup"><span data-stu-id="c653a-144">A unique identifier for the node within the model.</span></span> <span data-ttu-id="c653a-145">這項值不能被改變。</span><span class="sxs-lookup"><span data-stu-id="c653a-145">This value cannot be changed.</span></span>  
  
 <span data-ttu-id="c653a-146">若是決策樹模型，唯一名稱遵循下列慣例，這個慣例不適用於所有演算法：</span><span class="sxs-lookup"><span data-stu-id="c653a-146">For decision tree models, the unique names follow the following convention, which does not apply to all algorithms:</span></span>  
  
 <span data-ttu-id="c653a-147">任何特定節點的子節點全部都有相同的十六進位前置詞，後面接著另一個十六進位數字，代表子節點在父系內部的順序。</span><span class="sxs-lookup"><span data-stu-id="c653a-147">The child nodes of any particular node will all have the same hexadecimal prefix, followed by another hexadecimal number that represents the sequence of the child node within the parent.</span></span> <span data-ttu-id="c653a-148">您可以使用前置詞來推斷路徑。</span><span class="sxs-lookup"><span data-stu-id="c653a-148">You can use the prefixes to infer a path.</span></span>  
  
 <span data-ttu-id="c653a-149">NODE_TYPE</span><span class="sxs-lookup"><span data-stu-id="c653a-149">NODE_TYPE</span></span>  
 <span data-ttu-id="c653a-150">在決策樹模型中，會建立下列類型的節點：</span><span class="sxs-lookup"><span data-stu-id="c653a-150">In decision tree models, the following types of nodes are created:</span></span>  
  
|<span data-ttu-id="c653a-151">節點類型</span><span class="sxs-lookup"><span data-stu-id="c653a-151">Node Type</span></span>|<span data-ttu-id="c653a-152">描述</span><span class="sxs-lookup"><span data-stu-id="c653a-152">Description</span></span>|  
|---------------|-----------------|  
|<span data-ttu-id="c653a-153">1 (模型)</span><span class="sxs-lookup"><span data-stu-id="c653a-153">1 (Model)</span></span>|<span data-ttu-id="c653a-154">模型的根節點。</span><span class="sxs-lookup"><span data-stu-id="c653a-154">Root node for model.</span></span>|  
|<span data-ttu-id="c653a-155">2 (樹狀結構)</span><span class="sxs-lookup"><span data-stu-id="c653a-155">2 (Tree)</span></span>|<span data-ttu-id="c653a-156">在模型中分類樹狀結構的父節點。</span><span class="sxs-lookup"><span data-stu-id="c653a-156">Parent node for classification trees in the model.</span></span> <span data-ttu-id="c653a-157">標示為 **「All」**。</span><span class="sxs-lookup"><span data-stu-id="c653a-157">Labeled **"All"**.</span></span>|  
|<span data-ttu-id="c653a-158">3 (內部)</span><span class="sxs-lookup"><span data-stu-id="c653a-158">3 (Interior)</span></span>|<span data-ttu-id="c653a-159">內部分支的標頭，可在分類樹狀結構或迴歸樹狀結構中找到。</span><span class="sxs-lookup"><span data-stu-id="c653a-159">Head of interior branch, found within in a classification tree or regression tree.</span></span>|  
|<span data-ttu-id="c653a-160">4 (分佈)</span><span class="sxs-lookup"><span data-stu-id="c653a-160">4 (Distribution)</span></span>|<span data-ttu-id="c653a-161">分葉節點，可在分類樹狀結構或迴歸樹狀結構中找到。</span><span class="sxs-lookup"><span data-stu-id="c653a-161">Leaf node, found within a classification tree or regression tree.</span></span>|  
|<span data-ttu-id="c653a-162">25 (迴歸樹狀結構)</span><span class="sxs-lookup"><span data-stu-id="c653a-162">25 (Regression tree)</span></span>|<span data-ttu-id="c653a-163">在模型內迴歸樹狀結構的父節點。</span><span class="sxs-lookup"><span data-stu-id="c653a-163">Parent node for regression tree within the model.</span></span> <span data-ttu-id="c653a-164">標示為 **「All」**。</span><span class="sxs-lookup"><span data-stu-id="c653a-164">Labeled as **"All"**.</span></span>|  
  
 <span data-ttu-id="c653a-165">NODE_CAPTION</span><span class="sxs-lookup"><span data-stu-id="c653a-165">NODE_CAPTION</span></span>  
 <span data-ttu-id="c653a-166">提供顯示用途的好記名稱。</span><span class="sxs-lookup"><span data-stu-id="c653a-166">A friendly name for display purposes.</span></span>  
  
 <span data-ttu-id="c653a-167">在建立模型時，NODE_UNIQUE_NAME 的值會自動用來當做標題。</span><span class="sxs-lookup"><span data-stu-id="c653a-167">When you create a model, the value of NODE_UNIQUE_NAME is automatically used as the caption.</span></span> <span data-ttu-id="c653a-168">不過，您可以用程式設計的方式或使用檢視器來變更 NODE_CAPTION 的值，以更新群集的顯示名稱。</span><span class="sxs-lookup"><span data-stu-id="c653a-168">However, you can change the value for NODE_CAPTION to update the display name for the cluster, either programmatically or by using the viewer.</span></span> <span data-ttu-id="c653a-169">標題會透過模型自動產生。</span><span class="sxs-lookup"><span data-stu-id="c653a-169">The caption is automatically generated by the model.</span></span> <span data-ttu-id="c653a-170">標題的內容取決於模型的類型以及節點類型。</span><span class="sxs-lookup"><span data-stu-id="c653a-170">The content of the caption depends on the type of model, and the node type.</span></span>  
  
 <span data-ttu-id="c653a-171">在決策樹模型中，NODE_CAPTION 和 NODE_DESCRIPTION 的資訊不同，端視樹狀結構中的層級而定。</span><span class="sxs-lookup"><span data-stu-id="c653a-171">In a decision trees model, the NODE_CAPTION and the NODE_DESCRIPTION have different information, depending on the level in the tree.</span></span> <span data-ttu-id="c653a-172">如需詳細資訊與範例，請參閱 [節點標題與節點描述](#NodeCaption)。</span><span class="sxs-lookup"><span data-stu-id="c653a-172">For more information and examples, see [Node Caption and Node Description](#NodeCaption).</span></span>  
  
 <span data-ttu-id="c653a-173">CHILDREN_CARDINALITY</span><span class="sxs-lookup"><span data-stu-id="c653a-173">CHILDREN_CARDINALITY</span></span>  
 <span data-ttu-id="c653a-174">節點所擁有子系數目的估計。</span><span class="sxs-lookup"><span data-stu-id="c653a-174">An estimate of the number of children that the node has.</span></span>  
  
 <span data-ttu-id="c653a-175">**父節點** ：指出已製作模型之可預測屬性的數目。</span><span class="sxs-lookup"><span data-stu-id="c653a-175">**Parent node** Indicates the number of predictable attributes that were modeled.</span></span> <span data-ttu-id="c653a-176">每個可預測的屬性都會建立一個樹狀結構。</span><span class="sxs-lookup"><span data-stu-id="c653a-176">A tree is created for each predictable attribute.</span></span>  
  
 <span data-ttu-id="c653a-177">**樹狀節點** ：每個樹狀結構的 **All** 節點都會告訴您目標屬性使用多少個值。</span><span class="sxs-lookup"><span data-stu-id="c653a-177">**Tree node** The **All** node for each tree tells you how many values were used for the target attribute.</span></span>  
  
-   <span data-ttu-id="c653a-178">如果目標屬性是離散的，該值等於 `Missing` 狀態的相異值數目加 1。</span><span class="sxs-lookup"><span data-stu-id="c653a-178">If the target attribute is discrete, the value equals the number of distinct values plus 1 for the `Missing` state.</span></span>  
  
-   <span data-ttu-id="c653a-179">如果可預測的屬性是連續的，此值會告訴您有多少值區用於製作連續屬性的模型。</span><span class="sxs-lookup"><span data-stu-id="c653a-179">If the predictable attribute is continuous, the value tells you how many buckets were used to model the continuous attribute.</span></span>  
  
 <span data-ttu-id="c653a-180">**分葉節點** ：永遠為 0。</span><span class="sxs-lookup"><span data-stu-id="c653a-180">**Leaf nodes** Always 0.</span></span>  
  
 <span data-ttu-id="c653a-181">PARENT_UNIQUE_NAME</span><span class="sxs-lookup"><span data-stu-id="c653a-181">PARENT_UNIQUE_NAME</span></span>  
 <span data-ttu-id="c653a-182">節點之父系的唯一名稱。</span><span class="sxs-lookup"><span data-stu-id="c653a-182">The unique name of the node's parent.</span></span> <span data-ttu-id="c653a-183">任何根層級的節點都會傳回 NULL。</span><span class="sxs-lookup"><span data-stu-id="c653a-183">NULL is returned for any nodes at the root level.</span></span>  
  
 <span data-ttu-id="c653a-184">NODE_DESCRIPTION</span><span class="sxs-lookup"><span data-stu-id="c653a-184">NODE_DESCRIPTION</span></span>  
 <span data-ttu-id="c653a-185">節點的描述。</span><span class="sxs-lookup"><span data-stu-id="c653a-185">A description of the node.</span></span>  
  
 <span data-ttu-id="c653a-186">在決策樹模型中，NODE_CAPTION 和 NODE_DESCRIPTION 的資訊不同，端視樹狀結構中的層級而定。</span><span class="sxs-lookup"><span data-stu-id="c653a-186">In a decision trees model, the NODE_CAPTION and the NODE_DESCRIPTION have different information, depending on the level in the tree.</span></span>  
  
 <span data-ttu-id="c653a-187">如需詳細資訊與範例，請參閱 [節點標題與節點描述](#NodeCaption)。</span><span class="sxs-lookup"><span data-stu-id="c653a-187">For more information and examples, see [Node Caption and Node Description](#NodeCaption).</span></span>  
  
 <span data-ttu-id="c653a-188">NODE_RULE</span><span class="sxs-lookup"><span data-stu-id="c653a-188">NODE_RULE</span></span>  
 <span data-ttu-id="c653a-189">規則的 XML 描述，其中描述來自直屬父節點之目前節點的路徑。</span><span class="sxs-lookup"><span data-stu-id="c653a-189">An XML description of the rule that describes the path to the current node from its immediate parent node.</span></span>  
  
 <span data-ttu-id="c653a-190">如需詳細資訊與範例，請參閱 [節點規則與臨界規則](#NodeRule)。</span><span class="sxs-lookup"><span data-stu-id="c653a-190">For more information and examples, see [Node Rule and Marginal Rule](#NodeRule).</span></span>  
  
 <span data-ttu-id="c653a-191">MARGINAL_RULE</span><span class="sxs-lookup"><span data-stu-id="c653a-191">MARGINAL_RULE</span></span>  
 <span data-ttu-id="c653a-192">規則的 XML 描述，其中描述從模型父節點到目前節點的路徑。</span><span class="sxs-lookup"><span data-stu-id="c653a-192">An XML description of the rule that describes the path from the model parent node to the current node.</span></span>  
  
 <span data-ttu-id="c653a-193">如需詳細資訊，請參閱 [節點規則與臨界規則](#NodeRule)。</span><span class="sxs-lookup"><span data-stu-id="c653a-193">For more information, see [Node Rule and Marginal Rule](#NodeRule).</span></span>  
  
 <span data-ttu-id="c653a-194">NODE_PROBABILITY</span><span class="sxs-lookup"><span data-stu-id="c653a-194">NODE_PROBABILITY</span></span>  
 <span data-ttu-id="c653a-195">與此節點關聯的機率。</span><span class="sxs-lookup"><span data-stu-id="c653a-195">The probability associated with this node.</span></span>  
  
 <span data-ttu-id="c653a-196">如需詳細資訊，請參閱 [機率](#bkmk_NodeDist_Discrete)。</span><span class="sxs-lookup"><span data-stu-id="c653a-196">For more information, see [Probability](#bkmk_NodeDist_Discrete).</span></span>  
  
 <span data-ttu-id="c653a-197">MARGINAL_PROBABILITY</span><span class="sxs-lookup"><span data-stu-id="c653a-197">MARGINAL_PROBABILITY</span></span>  
 <span data-ttu-id="c653a-198">從父節點到達節點的機率。</span><span class="sxs-lookup"><span data-stu-id="c653a-198">The probability of reaching the node from the parent node.</span></span>  
  
 <span data-ttu-id="c653a-199">如需詳細資訊，請參閱 [機率](#bkmk_NodeDist_Discrete)。</span><span class="sxs-lookup"><span data-stu-id="c653a-199">For more information, see [Probability](#bkmk_NodeDist_Discrete).</span></span>  
  
 <span data-ttu-id="c653a-200">NODE_DISTRIBUTION</span><span class="sxs-lookup"><span data-stu-id="c653a-200">NODE_DISTRIBUTION</span></span>  
 <span data-ttu-id="c653a-201">包含節點之機率長條圖的資料表。</span><span class="sxs-lookup"><span data-stu-id="c653a-201">A table that contains the probability histogram of the node.</span></span> <span data-ttu-id="c653a-202">此資料表中的資訊會隨著可預測屬性為連續或離散變數而有所不同。</span><span class="sxs-lookup"><span data-stu-id="c653a-202">The information in this table differs depending on whether the predictable attribute is a continuous or discrete variable.</span></span>  
  
 <span data-ttu-id="c653a-203">**模型根節點** ：此資料表是空的。</span><span class="sxs-lookup"><span data-stu-id="c653a-203">**Model root node** This table is empty.</span></span>  
  
 <span data-ttu-id="c653a-204">**(All) 節點** ：包含完整模型的摘要。</span><span class="sxs-lookup"><span data-stu-id="c653a-204">**(All) node** Contains a summary for the model as a whole.</span></span>  
  
 <span data-ttu-id="c653a-205">**內部節點** ：包含其分葉節點的彙總統計資料。</span><span class="sxs-lookup"><span data-stu-id="c653a-205">**Interior node** Contains aggregated statistics for its leaf nodes.</span></span>  
  
 <span data-ttu-id="c653a-206">**分葉節點** ：假設路徑中的所有條件都引導至目前的分葉節點，則包含預測結果的支援與機率。</span><span class="sxs-lookup"><span data-stu-id="c653a-206">**Leaf node** Contains support and probability for the predicted outcomes given all the conditions in the path leading to the current leaf node.</span></span>  
  
 <span data-ttu-id="c653a-207">**迴歸節點** ：包含代表輸入和可預測屬性間關聯性的迴歸公式。</span><span class="sxs-lookup"><span data-stu-id="c653a-207">**Regression node** Contains regression formula that represents the relationship between the inputs and the predictable attribute.</span></span>  
  
 <span data-ttu-id="c653a-208">如需詳細資訊，請參閱＜ [離散屬性的節點分佈](#bkmk_NodeDist_Discrete) ＞和＜ [連續屬性的節點分佈](#bkmk_RegressionNodes)＞。</span><span class="sxs-lookup"><span data-stu-id="c653a-208">For more information, see [Node Distribution for Discrete Attributes](#bkmk_NodeDist_Discrete) and [Node Distribution for Continuous Attributes](#bkmk_RegressionNodes).</span></span>  
  
 <span data-ttu-id="c653a-209">NODE_SUPPORT</span><span class="sxs-lookup"><span data-stu-id="c653a-209">NODE_SUPPORT</span></span>  
 <span data-ttu-id="c653a-210">支援這個節點的案例數目。</span><span class="sxs-lookup"><span data-stu-id="c653a-210">The number of cases that support this node.</span></span>  
  
 <span data-ttu-id="c653a-211">MSOLAP_MODEL_COLUMN</span><span class="sxs-lookup"><span data-stu-id="c653a-211">MSOLAP_MODEL_COLUMN</span></span>  
 <span data-ttu-id="c653a-212">指出包含可預測屬性的資料行。</span><span class="sxs-lookup"><span data-stu-id="c653a-212">Indicates the column that contains the predictable attribute.</span></span>  
  
 <span data-ttu-id="c653a-213">MSOLAP_NODE_SCORE</span><span class="sxs-lookup"><span data-stu-id="c653a-213">MSOLAP_NODE_SCORE</span></span>  
 <span data-ttu-id="c653a-214">顯示與節點相關聯的分數。</span><span class="sxs-lookup"><span data-stu-id="c653a-214">Displays a score associated with the node.</span></span> <span data-ttu-id="c653a-215">如需詳細資訊，請參閱 [節點分數](#NodeScore)。</span><span class="sxs-lookup"><span data-stu-id="c653a-215">For more information, see [Node Score](#NodeScore).</span></span>  
  
 <span data-ttu-id="c653a-216">MSOLAP_NODE_SHORT_CAPTION</span><span class="sxs-lookup"><span data-stu-id="c653a-216">MSOLAP_NODE_SHORT_CAPTION</span></span>  
 <span data-ttu-id="c653a-217">主要用於顯示用途。</span><span class="sxs-lookup"><span data-stu-id="c653a-217">A label used for display purposes.</span></span>  
  
## <a name="remarks"></a><span data-ttu-id="c653a-218">備註</span><span class="sxs-lookup"><span data-stu-id="c653a-218">Remarks</span></span>  
 <span data-ttu-id="c653a-219">不像在貝式機率分類或類神經網路模型中找到的臨界統計資料節點，決策樹模型沒有儲存整個模型之統計資料的個別節點。</span><span class="sxs-lookup"><span data-stu-id="c653a-219">A decision trees model does not have a separate node that stores statistics for the entire model, unlike the marginal statistics node found in a Naive Bayes or neural network model.</span></span> <span data-ttu-id="c653a-220">但是此模型會針對每個可預測的屬性建立一個個別的樹狀結構，且 (All) 節點位於樹狀結構的頂端。</span><span class="sxs-lookup"><span data-stu-id="c653a-220">Instead, the model creates a separate tree for each predictable attribute, with an (All) node at the top of the tree.</span></span> <span data-ttu-id="c653a-221">樹狀結構彼此之間無關。</span><span class="sxs-lookup"><span data-stu-id="c653a-221">Each tree is independent of the others.</span></span> <span data-ttu-id="c653a-222">如果您的模型只包含一個可預測的屬性，則只有一個樹狀結構，因此只有一個 (All) 節點。</span><span class="sxs-lookup"><span data-stu-id="c653a-222">If your model contains only one predictable attribute, there is only one tree, and therefore only one (All) node.</span></span>  
  
 <span data-ttu-id="c653a-223">代表輸出屬性的每個樹狀結構都會另外細分為代表分岔的內部分支 (NODE_TYPE = 3)。</span><span class="sxs-lookup"><span data-stu-id="c653a-223">Each tree that represents an output attribute is additionally subdivided into interior branches (NODE_TYPE = 3) that represent splits.</span></span> <span data-ttu-id="c653a-224">每個樹狀結構都包含關於目標屬性分佈的統計資料。</span><span class="sxs-lookup"><span data-stu-id="c653a-224">Each of these trees contains statistics about the distribution of the target attribute.</span></span> <span data-ttu-id="c653a-225">此外，每個分葉節點 (NODE_TYPE = 4) 都包含描述輸入屬性及其值的統計資料，以及支援每個屬性和值配對之案例的數目。</span><span class="sxs-lookup"><span data-stu-id="c653a-225">In addition, each leaf node (NODE_TYPE = 4) contains statistics that describe input attributes and their values, together with the number of cases in support of each attribute-value pair.</span></span> <span data-ttu-id="c653a-226">因此，在決策樹的任何分支中，您可以輕鬆檢視資料的機率或分佈，而不必查詢來源資料。</span><span class="sxs-lookup"><span data-stu-id="c653a-226">Therefore, in any branch of a decision tree, you can view the probabilities or the distribution of data easily without having to query the source data.</span></span> <span data-ttu-id="c653a-227">樹狀結構的每個層級都必須代表其直屬子節點的總和。</span><span class="sxs-lookup"><span data-stu-id="c653a-227">Each level of the tree necessarily represents the sum of its immediate child nodes.</span></span>  
  
 <span data-ttu-id="c653a-228">如需如何擷取這些統計資料的範例，請參閱 [決策樹模型查詢範例](decision-trees-model-query-examples.md)。</span><span class="sxs-lookup"><span data-stu-id="c653a-228">For examples of how to retrieve these statistics, see [Decision Trees Model Query Examples](decision-trees-model-query-examples.md).</span></span>  
  
## <a name="example-of-decision-tree-structure"></a><span data-ttu-id="c653a-229">決策樹結構的範例</span><span class="sxs-lookup"><span data-stu-id="c653a-229">Example of Decision Tree Structure</span></span>  
 <span data-ttu-id="c653a-230">若要了解決策樹如何運作，請考慮使用範例，例如，AdventureWorks 自行車購買者案例。</span><span class="sxs-lookup"><span data-stu-id="c653a-230">To understand how a decision tree works, consider an example, such as the AdventureWorks bike buyer scenario.</span></span> <span data-ttu-id="c653a-231">假設可預測的屬性為客戶購買的項目，決策樹演算法會嘗試在您提供的所有輸入中找出資料的一個資料行，可以用最有效的方式偵測到可能會購買自行車的客戶，以及可能不會購買自行車的客戶。</span><span class="sxs-lookup"><span data-stu-id="c653a-231">Assuming that the predictable attribute is customer purchases, the decision trees algorithm tries to find one column of data, among all the inputs that you provided, that most effectively detects the customers that are likely to purchase a bike and those who are unlikely to buy a bike.</span></span> <span data-ttu-id="c653a-232">例如，此模型可能會發現「年齡」是購買行為的最佳指標。</span><span class="sxs-lookup"><span data-stu-id="c653a-232">For example, the model might find that Age is the best indicator of purchasing behavior.</span></span> <span data-ttu-id="c653a-233">特別是，超過 30 歲的客戶很可能購買自行車，而其他所有客戶則可能不會購買。</span><span class="sxs-lookup"><span data-stu-id="c653a-233">Specifically, that the customers over the age of 30 are very likely to purchase a bike, and all other customers are unlikely to make a purchase.</span></span> <span data-ttu-id="c653a-234">在這個案例中，此模型會在 [Age] 屬性上建立一個 *「分岔」* (Split)。</span><span class="sxs-lookup"><span data-stu-id="c653a-234">In this scenario, the model creates a *split* on the Age attribute.</span></span> <span data-ttu-id="c653a-235">也就是說，樹狀結構分成兩個分支，其中一個分支包含超過 30 歲的客戶，另一個分支則包含 30 歲以下的客戶。</span><span class="sxs-lookup"><span data-stu-id="c653a-235">That means that the tree divides into two branches, one containing customers over the age of 30, and the other containing customers under 30.</span></span> <span data-ttu-id="c653a-236">在模型結構中，新的分支會以兩個新的內部樹狀結構 (NODE_TYPE = 3) 代表。</span><span class="sxs-lookup"><span data-stu-id="c653a-236">The new branches are represented in the model structure as two new interior trees (NODE_TYPE = 3).</span></span>  
  
 <span data-ttu-id="c653a-237">此模型會針對每個分支，繼續尋找用於區分客戶的其他屬性。</span><span class="sxs-lookup"><span data-stu-id="c653a-237">For each branch, the model continues to look for additional attributes to use in differentiating customers.</span></span> <span data-ttu-id="c653a-238">如果資料中的證據不足，無法繼續建立客戶的子群組，此模型會停止建立樹狀結構。</span><span class="sxs-lookup"><span data-stu-id="c653a-238">If there is insufficient evidence in the data to continue creating subgroups of customers, the model stops building the tree.</span></span> <span data-ttu-id="c653a-239">此模型也會在節點中的案例數太小而無法繼續時，停止建立樹狀結構，而不管分岔是否妥當，或者值為 Null 或遺漏。</span><span class="sxs-lookup"><span data-stu-id="c653a-239">The model will also stop building the tree whenever the number of cases in the node is too small to continue, regardless of how good the split is, or if the value is null or missing.</span></span> <span data-ttu-id="c653a-240">早期停止樹狀結構的成長，您就可以防止模型與特定一組資料的定型太接近。</span><span class="sxs-lookup"><span data-stu-id="c653a-240">By stopping the growth of the tree early, you prevent the model from training too closely to one particular set of data.</span></span>  
  
 <span data-ttu-id="c653a-241">每個內部樹狀節點都包含分葉節點，可提供給定目前分類結果的細分結果。</span><span class="sxs-lookup"><span data-stu-id="c653a-241">Each interior tree node contains leaf nodes that provide a breakdown of the outcomes given the current classification results.</span></span> <span data-ttu-id="c653a-242">例如，您可能有一個代表 Age >= 30，而且 Gender = Male 的內部節點。</span><span class="sxs-lookup"><span data-stu-id="c653a-242">For example, you might have an interior node that represents Age >= 30 and Gender = Male.</span></span> <span data-ttu-id="c653a-243">此群組的節點會顯示此類別中購買的客戶數目，或者未購買的客戶數目。</span><span class="sxs-lookup"><span data-stu-id="c653a-243">The node for this group shows you how many customers in this category purchased or did not purchase something.</span></span> <span data-ttu-id="c653a-244">例如，分類可能包含下列樹狀結構分岔：</span><span class="sxs-lookup"><span data-stu-id="c653a-244">For example, the classification might contain the following tree splits:</span></span>  
  
|<span data-ttu-id="c653a-245">內部樹狀結構</span><span class="sxs-lookup"><span data-stu-id="c653a-245">Interior tree</span></span>|<span data-ttu-id="c653a-246">分割</span><span class="sxs-lookup"><span data-stu-id="c653a-246">Split</span></span>|  
|-------------------|-----------|  
|<span data-ttu-id="c653a-247">Age >= 30</span><span class="sxs-lookup"><span data-stu-id="c653a-247">Age >= 30</span></span>|<span data-ttu-id="c653a-248">Age >= 30 而且 Gender = Male</span><span class="sxs-lookup"><span data-stu-id="c653a-248">Age >= 30 and Gender = Male</span></span>|  
||<span data-ttu-id="c653a-249">Age >= 30 而且 Gender = Female</span><span class="sxs-lookup"><span data-stu-id="c653a-249">Age >= 30 and Gender = Female</span></span>|  
|<span data-ttu-id="c653a-250">Age < 30</span><span class="sxs-lookup"><span data-stu-id="c653a-250">Age < 30</span></span>|<span data-ttu-id="c653a-251">Age < 30 而且 Gender = Male</span><span class="sxs-lookup"><span data-stu-id="c653a-251">Age < 30 and Gender = Male</span></span>|  
||<span data-ttu-id="c653a-252">年齡 \< 30 和性別 = 女性</span><span class="sxs-lookup"><span data-stu-id="c653a-252">Age \< 30 and Gender = Female</span></span>|  
  
 <span data-ttu-id="c653a-253">當您使用決策樹模型進行預測時，此模型會採用您所提供的屬性當做引數，然後遵照屬性的路徑向下到樹狀結構。</span><span class="sxs-lookup"><span data-stu-id="c653a-253">When you use a decision tree model for prediction, the model takes the attributes that you provide to it as arguments and follows the path of the attributes down through the tree.</span></span> <span data-ttu-id="c653a-254">一般而言，所有預測都會到分葉，而內部節點則僅用於分類。</span><span class="sxs-lookup"><span data-stu-id="c653a-254">In general, all predictions go to a leaf, and the interior nodes are used only for classification.</span></span>  
  
 <span data-ttu-id="c653a-255">分葉節點的 NODE_TYPE 永遠都為 4 (分佈)，而且包含的長條圖會根據您提供的屬性，顯示每個結果的機率 (購買或不購買)。</span><span class="sxs-lookup"><span data-stu-id="c653a-255">A leaf node always has a NODE_TYPE of 4 (Distribution) and contains a histogram that tells the probability of each outcome (purchase or not purchase) given the attributes you provide.</span></span> <span data-ttu-id="c653a-256">例如，如果您要求預測超過 60 歲的男性新客戶，此模型將會查詢對應的節點 (Age > 30 而且 Gender = Male)，然後傳回您指定之結果的機率。</span><span class="sxs-lookup"><span data-stu-id="c653a-256">For example, if you ask for a prediction for a new customer who is a male over 60, the model will look up the corresponding node (Age > 30 and Gender = Male) and then return the probability for the outcome that you specify.</span></span> <span data-ttu-id="c653a-257">這些機率儲存在節點的 [NODE_DISTRIBUTION](#bkmk_NodeDist_Discrete) 資料表中。</span><span class="sxs-lookup"><span data-stu-id="c653a-257">These probabilities are stored in the [NODE_DISTRIBUTION](#bkmk_NodeDist_Discrete) table for the node.</span></span>  
  
 <span data-ttu-id="c653a-258">如果可預測的屬性是連續數字，此演算法會嘗試建立迴歸公式，以製作可預測屬性和輸入之間關聯性的模型。</span><span class="sxs-lookup"><span data-stu-id="c653a-258">If the predictable attribute is a continuous number, the algorithm tries to create a regression formula that models the relationship between the predictable attribute and the inputs.</span></span>  
  
###  <a name="node-caption-and-node-description"></a><a name="NodeCaption"></a><span data-ttu-id="c653a-259">節點標題與節點描述</span><span class="sxs-lookup"><span data-stu-id="c653a-259">Node Caption and Node Description</span></span>  
 <span data-ttu-id="c653a-260">在決策樹模型中，節點標題與節點描述包含類似的資訊。</span><span class="sxs-lookup"><span data-stu-id="c653a-260">In a decision tree model, the node caption and node description contain similar information.</span></span> <span data-ttu-id="c653a-261">不過，節點描述更為完整，而且在您向分葉節點移得更近時，會包含更多資訊。</span><span class="sxs-lookup"><span data-stu-id="c653a-261">However, the node description is more complete and contains more information as you move closer to the leaf nodes.</span></span> <span data-ttu-id="c653a-262">節點標題與節點描述都是當地語系化的字串。</span><span class="sxs-lookup"><span data-stu-id="c653a-262">Both the node caption and node description are localized strings.</span></span>  
  
|||  
|-|-|  
|<span data-ttu-id="c653a-263">**NODE_CAPTION**</span><span class="sxs-lookup"><span data-stu-id="c653a-263">**NODE_CAPTION**</span></span>|<span data-ttu-id="c653a-264">顯示區別相對於父節點之該特定節點的屬性。</span><span class="sxs-lookup"><span data-stu-id="c653a-264">Displays the attribute that distinguishes that particular node relative to the parent node.</span></span> <span data-ttu-id="c653a-265">節點標題會定義以母體為基礎之分岔條件的子區段。</span><span class="sxs-lookup"><span data-stu-id="c653a-265">The node caption defines a sub-segment of the population based the split condition.</span></span> <span data-ttu-id="c653a-266">例如，如果分割是在 [Age]，而它是三向分割，則三個子節點的節點標題可能是 "[Age] < 40"、"40 <= [Age] \< 50", "[Age] > = 50"。</span><span class="sxs-lookup"><span data-stu-id="c653a-266">For example, if the split was on [Age] and it was a three-way split, the node captions for the three child nodes might be "[Age] < 40", "40 <= [Age] \< 50", "[Age] >= 50".</span></span>|  
|<span data-ttu-id="c653a-267">**NODE_DESCRIPTION**</span><span class="sxs-lookup"><span data-stu-id="c653a-267">**NODE_DESCRIPTION**</span></span>|<span data-ttu-id="c653a-268">包含區別各節點之屬性的完整清單，從模型父節點開始。</span><span class="sxs-lookup"><span data-stu-id="c653a-268">Contains a full list of the attributes that distinguish that node from other nodes, starting from the model parent node.</span></span> <span data-ttu-id="c653a-269">例如，Product name = Apple 而且 Color = Red。</span><span class="sxs-lookup"><span data-stu-id="c653a-269">For example, Product name = Apple and Color = Red.</span></span>|  
  
###  <a name="node-rule-and-marginal-rule"></a><a name="NodeRule"></a> <span data-ttu-id="c653a-270">節點規則與臨界規則</span><span class="sxs-lookup"><span data-stu-id="c653a-270">Node Rule and Marginal Rule</span></span>  
 <span data-ttu-id="c653a-271">NODE_RULE 和 MARGINAL_RULE 資料行包含與 NODE_CAPTION 和 NODE_DESCRIPTION 資料行相同的資訊，但是將資訊表示為 XML 片段。</span><span class="sxs-lookup"><span data-stu-id="c653a-271">The NODE_RULE and MARGINAL_RULE columns contain the same information as the NODE_CAPTION and NODE_DESCRIPTION columns, but represent the information as XML fragments.</span></span> <span data-ttu-id="c653a-272">節點規則為 XML 版本的完整路徑，而臨界規則會指出最近的分岔。</span><span class="sxs-lookup"><span data-stu-id="c653a-272">The node rule is an XML version of the full path, whereas the marginal rule indicates the most recent split.</span></span>  
  
 <span data-ttu-id="c653a-273">以 XML 片段表示的屬性可以很簡單，也可以很複雜。</span><span class="sxs-lookup"><span data-stu-id="c653a-273">The attribute represented by the XML fragment can be either simple or complex.</span></span> <span data-ttu-id="c653a-274">簡單的屬性包含模型資料行的名稱以及屬性的值。</span><span class="sxs-lookup"><span data-stu-id="c653a-274">A simple attribute contains the name of the model column, and the value of the attribute.</span></span> <span data-ttu-id="c653a-275">如果模型資料行包含巢狀資料表，巢狀資料表屬性會以資料表名稱、索引鍵值和屬性的串連表示。</span><span class="sxs-lookup"><span data-stu-id="c653a-275">If the model column contains a nested table, the nested table attribute is represented as a concatenation of the table name, the key value, and the attribute.</span></span>  
  
> [!NOTE]  
>  [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]<span data-ttu-id="c653a-276">[!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)]支援2.0 版的 PMML standard，其中包含支援使用嵌套資料表的延伸模組。</span><span class="sxs-lookup"><span data-stu-id="c653a-276">[!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] supports version 2.0 of the PMML standard, with extensions to support the use of nested table.</span></span> <span data-ttu-id="c653a-277">如果您的資料包含巢狀資料表，而且您要產生 PMML 版本的模型，模型中包含預測的所有元素都會標示為闊重模組。</span><span class="sxs-lookup"><span data-stu-id="c653a-277">If your data contains nested tables and you generate a PMML version of the model, all elements in the model that include the predicates are marked as an extension.</span></span>  
  
###  <a name="node-distribution-for-discrete-attributes"></a><a name="bkmk_NodeDist_Discrete"></a><span data-ttu-id="c653a-278">離散屬性的節點分佈</span><span class="sxs-lookup"><span data-stu-id="c653a-278">Node Distribution for Discrete Attributes</span></span>  
 <span data-ttu-id="c653a-279">在決策樹模型中，NODE_DISTRIBUTION 資料表包含實用的統計資料。</span><span class="sxs-lookup"><span data-stu-id="c653a-279">In a decision trees model, the NODE_DISTRIBUTION table contains useful statistics.</span></span> <span data-ttu-id="c653a-280">不過，統計資料的類型取決於樹狀結構預測離散屬性還是連續屬性。</span><span class="sxs-lookup"><span data-stu-id="c653a-280">However, the type of statistics depends on whether the tree predicts a discrete or continuous attribute.</span></span> <span data-ttu-id="c653a-281">本節描述離散屬性之節點分佈統計資料的意義。</span><span class="sxs-lookup"><span data-stu-id="c653a-281">This section describes the meaning of the node distribution statistics for discrete attributes.</span></span>  
  
#### <a name="attribute-name-and-attribute-value"></a><span data-ttu-id="c653a-282">屬性名稱與屬性值</span><span class="sxs-lookup"><span data-stu-id="c653a-282">Attribute Name and Attribute Value</span></span>  
 <span data-ttu-id="c653a-283">在分類樹狀結構中，屬性名稱永遠包含可預測資料行的名稱。</span><span class="sxs-lookup"><span data-stu-id="c653a-283">In a classification tree, the attribute name always contains the name of the predictable column.</span></span> <span data-ttu-id="c653a-284">這個值會告訴您樹狀結構預測的項目。</span><span class="sxs-lookup"><span data-stu-id="c653a-284">This value tells you what the tree predicts.</span></span> <span data-ttu-id="c653a-285">由於單一樹狀結構永遠代表單一可預測的屬性，因此這個值在樹狀結構中會重複出現。</span><span class="sxs-lookup"><span data-stu-id="c653a-285">Because a single tree always represents a single predictable attribute, this value is repeated throughout the tree.</span></span>  
  
 <span data-ttu-id="c653a-286">若是離散資料類型，屬性值欄位會列出可預測資料行的可能值，加上 `Missing` 值。</span><span class="sxs-lookup"><span data-stu-id="c653a-286">For a discrete data type, the attribute value field lists the possible values of the predictable column, plus the `Missing` value.</span></span>  
  
#### <a name="support"></a><span data-ttu-id="c653a-287">支援</span><span class="sxs-lookup"><span data-stu-id="c653a-287">Support</span></span>  
 <span data-ttu-id="c653a-288">每個節點的支援值都會告訴提此節點包含多少案例。</span><span class="sxs-lookup"><span data-stu-id="c653a-288">The support value for each node tells you how many cases are included in this node.</span></span> <span data-ttu-id="c653a-289">您應該在 (All) 層級看到用於定型模型之案例的完整計數。</span><span class="sxs-lookup"><span data-stu-id="c653a-289">At the (All) level, you should see the complete count of cases that were used to train the model.</span></span> <span data-ttu-id="c653a-290">對於樹狀結構中的每個分岔，支援值是分組到樹狀結構該節點之案例的計數。</span><span class="sxs-lookup"><span data-stu-id="c653a-290">For each split in the tree, the support value is the count of cases that were grouped into that node of the tree.</span></span> <span data-ttu-id="c653a-291">分葉節點中的案例總和務必等於樹狀結構父節點中的案例計數。</span><span class="sxs-lookup"><span data-stu-id="c653a-291">The sum of cases in the leaf nodes necessarily equals the count of cases in the parent node of the tree.</span></span>  
  
 <span data-ttu-id="c653a-292">對於代表連續屬性的節點，資料中出現的 Null 可能會導致某些反直覺式結果。</span><span class="sxs-lookup"><span data-stu-id="c653a-292">For nodes that represent continuous attributes, the presence of nulls in the data might lead to some counterintuitive results.</span></span> <span data-ttu-id="c653a-293">例如，如果有 m 個案例，平均值會計算為 sum(all cases)/n，其中 n 是小於 m 的數字，而 m-n 表示遺漏值之案例的計數。</span><span class="sxs-lookup"><span data-stu-id="c653a-293">For example, if there are m cases, a mean value would be calculated as sum(all cases)/n, where n is a number less than m, and m-n indicates the count of cases with missing values.</span></span> <span data-ttu-id="c653a-294">支援也會以 n 表示。</span><span class="sxs-lookup"><span data-stu-id="c653a-294">Support is also represented as n.</span></span>  
  
#### <a name="probability"></a><span data-ttu-id="c653a-295">機率</span><span class="sxs-lookup"><span data-stu-id="c653a-295">Probability</span></span>  
 <span data-ttu-id="c653a-296">與每個節點關聯的機率會告訴您整個資料集中所有案例都會在此特定節點結束的機率。</span><span class="sxs-lookup"><span data-stu-id="c653a-296">The probability associated with each node tells you the probability that any case in the whole data set would end up in this particular node.</span></span> <span data-ttu-id="c653a-297">機率分數會同時針對整個樹狀結構和直屬分岔計算。</span><span class="sxs-lookup"><span data-stu-id="c653a-297">Probability scores are computed both for the tree as a whole, and for the immediate split.</span></span>  
  
 <span data-ttu-id="c653a-298">例如，下列資料表顯示非常簡單的模型，其中包含 100 個案例。</span><span class="sxs-lookup"><span data-stu-id="c653a-298">For example, the following table shows a very simple model, with 100 cases.</span></span>  
  
|<span data-ttu-id="c653a-299">內部樹狀結構</span><span class="sxs-lookup"><span data-stu-id="c653a-299">Interior tree</span></span>|<span data-ttu-id="c653a-300">案例</span><span class="sxs-lookup"><span data-stu-id="c653a-300">Cases</span></span>|<span data-ttu-id="c653a-301">分葉節點</span><span class="sxs-lookup"><span data-stu-id="c653a-301">Leaf node</span></span>|<span data-ttu-id="c653a-302">案例</span><span class="sxs-lookup"><span data-stu-id="c653a-302">Cases</span></span>|<span data-ttu-id="c653a-303">相對於父節點的機率</span><span class="sxs-lookup"><span data-stu-id="c653a-303">Probability relative to parent node</span></span>|<span data-ttu-id="c653a-304">相對於最上層節點的機率</span><span class="sxs-lookup"><span data-stu-id="c653a-304">Probability relative to top node</span></span>|  
|-------------------|-----------|---------------|-----------|-----------------------------------------|--------------------------------------|  
|<span data-ttu-id="c653a-305">Age >= 30</span><span class="sxs-lookup"><span data-stu-id="c653a-305">Age >= 30</span></span>|<span data-ttu-id="c653a-306">60</span><span class="sxs-lookup"><span data-stu-id="c653a-306">60</span></span>|<span data-ttu-id="c653a-307">Age >= 30 而且 Gender = Male</span><span class="sxs-lookup"><span data-stu-id="c653a-307">Age >= 30 and Gender = Male</span></span>|<span data-ttu-id="c653a-308">50</span><span class="sxs-lookup"><span data-stu-id="c653a-308">50</span></span>|<span data-ttu-id="c653a-309">50/60 = .83</span><span class="sxs-lookup"><span data-stu-id="c653a-309">50/60 = .83</span></span>|<span data-ttu-id="c653a-310">50/100 = .5</span><span class="sxs-lookup"><span data-stu-id="c653a-310">50/100 = .5</span></span>|  
|||<span data-ttu-id="c653a-311">Age >= 30 而且 Gender = Female</span><span class="sxs-lookup"><span data-stu-id="c653a-311">Age >= 30 and Gender = Female</span></span>|<span data-ttu-id="c653a-312">10</span><span class="sxs-lookup"><span data-stu-id="c653a-312">10</span></span>|<span data-ttu-id="c653a-313">10/60 = .16</span><span class="sxs-lookup"><span data-stu-id="c653a-313">10/60 = .16</span></span>|<span data-ttu-id="c653a-314">10/100 = .10</span><span class="sxs-lookup"><span data-stu-id="c653a-314">10/100 = .10</span></span>|  
|<span data-ttu-id="c653a-315">Age < 30</span><span class="sxs-lookup"><span data-stu-id="c653a-315">Age < 30</span></span>|<span data-ttu-id="c653a-316">40</span><span class="sxs-lookup"><span data-stu-id="c653a-316">40</span></span>|<span data-ttu-id="c653a-317">Age < 30 而且 Gender = Male</span><span class="sxs-lookup"><span data-stu-id="c653a-317">Age < 30 and Gender = Male</span></span>|<span data-ttu-id="c653a-318">30</span><span class="sxs-lookup"><span data-stu-id="c653a-318">30</span></span>|<span data-ttu-id="c653a-319">30/40 = .75</span><span class="sxs-lookup"><span data-stu-id="c653a-319">30/40 = .75</span></span>|<span data-ttu-id="c653a-320">30/100 = .30</span><span class="sxs-lookup"><span data-stu-id="c653a-320">30/100 = .30</span></span>|  
|||<span data-ttu-id="c653a-321">Age < 30 而且 Gender = Female</span><span class="sxs-lookup"><span data-stu-id="c653a-321">Age < 30 and Gender = Female</span></span>|<span data-ttu-id="c653a-322">10</span><span class="sxs-lookup"><span data-stu-id="c653a-322">10</span></span>|<span data-ttu-id="c653a-323">10/40 = .25</span><span class="sxs-lookup"><span data-stu-id="c653a-323">10/40 = .25</span></span>|<span data-ttu-id="c653a-324">10/100 = .10</span><span class="sxs-lookup"><span data-stu-id="c653a-324">10/100 = .10</span></span>|  
  
 <span data-ttu-id="c653a-325">在所有模型中進行小調整就可以計算可能的遺漏值。</span><span class="sxs-lookup"><span data-stu-id="c653a-325">A small adjustment is made in all models to account for possible missing values.</span></span> <span data-ttu-id="c653a-326">針對連續屬性，每個值或值範圍都會以狀態表示 (例如，Age \<30, Age = 30, and Age > 30) 而且機率的計算方式如下：狀態存在 (值 = 1) ，其他狀態存在 (值 = 0) ，狀態為 `Missing` 。</span><span class="sxs-lookup"><span data-stu-id="c653a-326">For continuous attributes, each value or range of values is represented as a state (for example, Age \<30, Age = 30, and Age >30) and the probabilities are calculated as follows: state exists (value = 1), some other state exists (value = 0), state is `Missing`.</span></span> <span data-ttu-id="c653a-327">如需如何調整機率來表示遺漏值的詳細資訊，請參閱[遺漏值 &#40;Analysis Services - 資料採礦&#41;](missing-values-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="c653a-327">For more information about how probabilities are adjusted to represent missing values, see [Missing Values &#40;Analysis Services - Data Mining&#41;](missing-values-analysis-services-data-mining.md).</span></span>  
  
 <span data-ttu-id="c653a-328">每個節點的機率幾乎都直接從分佈計算，如下所示：</span><span class="sxs-lookup"><span data-stu-id="c653a-328">The probabilities for each node are calculated almost directly from the distribution, as follows:</span></span>  
  
 <span data-ttu-id="c653a-329">機率 = (狀態的支援 + 先前狀態的支援) / (節點支援加上先前節點支援)</span><span class="sxs-lookup"><span data-stu-id="c653a-329">Probability = (support for state + support for prior state) / (node support plus the prior node support)</span></span>  
  
 [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] <span data-ttu-id="c653a-330">會使用每個節點的機率比較已儲存的機率與先前的機率來判斷父節點到子節點的路徑是否表示堅定的推斷。</span><span class="sxs-lookup"><span data-stu-id="c653a-330">uses probabilities for each node to compare the stored probability with the prior probability to determine whether the path from the parent to the child node indicates a strong inference.</span></span>  
  
 <span data-ttu-id="c653a-331">進行預測時，分佈的機率必須與節點的機率對稱，使機率平穩。</span><span class="sxs-lookup"><span data-stu-id="c653a-331">When making predictions, the probability of the distribution must be balanced with the probability of the node, to smoothen the probabilities.</span></span> <span data-ttu-id="c653a-332">例如，如果樹狀結構中的分岔以 9000/1000 的比例分隔案例，該樹狀結構就非常不對稱。</span><span class="sxs-lookup"><span data-stu-id="c653a-332">For example, if a split in the tree separates cases by a ratio of 9000/1000, the tree is very unbalanced.</span></span> <span data-ttu-id="c653a-333">因此，來自小分支的預測加權不應該與來自包含多個案例之分支的預測加權相同。</span><span class="sxs-lookup"><span data-stu-id="c653a-333">As a result, a prediction coming from the small branch should not carry the same weight as a prediction coming from a branch with many cases.</span></span>  
  
#### <a name="variance"></a><span data-ttu-id="c653a-334">變異數</span><span class="sxs-lookup"><span data-stu-id="c653a-334">Variance</span></span>  
 <span data-ttu-id="c653a-335">「變異數」是在給定預期分佈的情況下，值如何在範例中散佈的量值。</span><span class="sxs-lookup"><span data-stu-id="c653a-335">Variance is a measure of how scattered values in a sample are, given an expected distribution.</span></span> <span data-ttu-id="c653a-336">若是離散值，定義的變異數為 0。</span><span class="sxs-lookup"><span data-stu-id="c653a-336">For discrete values, the variance is 0 by definition.</span></span>  
  
 <span data-ttu-id="c653a-337">如需如何計算連續值之變異數的資訊，請參閱[線性迴歸模型的採礦模型內容 &#40;Analysis Services - 資料採礦&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="c653a-337">For information about how variance is calculated for continuous values, see [Mining Model Content for Linear Regression Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md).</span></span>  
  
#### <a name="value-type"></a><span data-ttu-id="c653a-338">數值類型</span><span class="sxs-lookup"><span data-stu-id="c653a-338">Value Type</span></span>  
 <span data-ttu-id="c653a-339">值類型資料行會提供 NODE_DISTRIBUTION 資料表中的其他資料行所提供之數值意義的相關資訊。</span><span class="sxs-lookup"><span data-stu-id="c653a-339">The value type column provides information about the meaning of the numeric value provided in the other columns in the NODE_DISTRIBUTION table.</span></span> <span data-ttu-id="c653a-340">您可以使用查詢中的值類型，從巢狀資料表擷取特定的資料列。</span><span class="sxs-lookup"><span data-stu-id="c653a-340">You can use the value type in queries to retrieve specific rows from the nested tables.</span></span> <span data-ttu-id="c653a-341">如需範例，請參閱 [決策樹模型查詢範例](decision-trees-model-query-examples.md)。</span><span class="sxs-lookup"><span data-stu-id="c653a-341">For examples, see [Decision Trees Model Query Examples](decision-trees-model-query-examples.md).</span></span>  
  
 <span data-ttu-id="c653a-342">在 <xref:Microsoft.AnalysisServices.AdomdClient.MiningValueType> 列舉的類型中，下列類型用於分類樹狀結構。</span><span class="sxs-lookup"><span data-stu-id="c653a-342">Of the types in the <xref:Microsoft.AnalysisServices.AdomdClient.MiningValueType> enumeration, the following are used in classification trees.</span></span>  
  
|<span data-ttu-id="c653a-343">值類型</span><span class="sxs-lookup"><span data-stu-id="c653a-343">Value type</span></span>|<span data-ttu-id="c653a-344">描述</span><span class="sxs-lookup"><span data-stu-id="c653a-344">Description</span></span>|  
|----------------|-----------------|  
|<span data-ttu-id="c653a-345">1 (遺漏)</span><span class="sxs-lookup"><span data-stu-id="c653a-345">1 (Missing)</span></span>|<span data-ttu-id="c653a-346">指出與遺漏值相關的計數、機率或其他統計資料。</span><span class="sxs-lookup"><span data-stu-id="c653a-346">Indicates a count, probability, or other statistic related to missing values.</span></span>|  
|<span data-ttu-id="c653a-347">4 (離散)</span><span class="sxs-lookup"><span data-stu-id="c653a-347">4 (Discrete)</span></span>|<span data-ttu-id="c653a-348">指出與離散或離散化值相關的計數、機率或其他統計資料。</span><span class="sxs-lookup"><span data-stu-id="c653a-348">Indicates a count, probability, or other statistic related to a discrete or discretized value.</span></span>|  
  
 <span data-ttu-id="c653a-349">如果模型包含連續的可預測屬性，樹狀結構可能也包含對迴歸公式而言唯一的值類型。</span><span class="sxs-lookup"><span data-stu-id="c653a-349">If the model includes a continuous predictable attribute, the tree might also contain value types that are unique to regression formulas.</span></span> <span data-ttu-id="c653a-350">如需用於迴歸樹狀結構之實值型別的清單，請參閱[線性迴歸模型的採礦模型內容 &#40;Analysis Services - 資料採礦&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="c653a-350">For a list of the value types that are used in regression trees, see [Mining Model Content for Linear Regression Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md).</span></span>  
  
###  <a name="node-score"></a><a name="NodeScore"></a> <span data-ttu-id="c653a-351">節點分數</span><span class="sxs-lookup"><span data-stu-id="c653a-351">Node Score</span></span>  
 <span data-ttu-id="c653a-352">節點分數代表樹狀結構每個層級上稍微不同的資訊。</span><span class="sxs-lookup"><span data-stu-id="c653a-352">The node score represents slightly different information at each level of the tree.</span></span> <span data-ttu-id="c653a-353">一般而言，此分數是一個數值，可告訴您條件式分割所達成的分岔效果。</span><span class="sxs-lookup"><span data-stu-id="c653a-353">In general, the score is a numeric value that tells you how good a split was achieved by splitting on the condition.</span></span> <span data-ttu-id="c653a-354">此值會以雙線表示，其中的值越大越好。</span><span class="sxs-lookup"><span data-stu-id="c653a-354">The value is represented as a double, where a higher value is better.</span></span>  
  
 <span data-ttu-id="c653a-355">根據定義，模型節點與所有分葉節點的節點分數都為 0。</span><span class="sxs-lookup"><span data-stu-id="c653a-355">By definition, the model node and all leaf nodes have a node score of 0.</span></span>  
  
 <span data-ttu-id="c653a-356">若是代表每個樹狀結構最上層的 (All) 節點，MSOLAP_NODE_SCORE 資料行會在整個樹狀結構中包含最佳的分岔準則。</span><span class="sxs-lookup"><span data-stu-id="c653a-356">For the (All) node that represents the top of each tree, the MSOLAP_NODE_SCORE column contains the best split score in the whole tree.</span></span>  
  
 <span data-ttu-id="c653a-357">若是樹狀結構中的其他所有節點 (分葉節點除外)，每個節點的分數都代表目前節點的最佳分岔準則，減去父節點的分岔準則。</span><span class="sxs-lookup"><span data-stu-id="c653a-357">For all other nodes in the tree (except leaf nodes), the score for each node represents the best split score for the current node, minus the split score for the parent node.</span></span> <span data-ttu-id="c653a-358">父節點的分岔準則通常永遠比任何其中一個子節點的分岔準則好。</span><span class="sxs-lookup"><span data-stu-id="c653a-358">Typically, the split score for a parent node should always be better than the split score on any one of its child nodes.</span></span> <span data-ttu-id="c653a-359">那是因為理論上決策樹模型會先針對最重要的屬性分岔。</span><span class="sxs-lookup"><span data-stu-id="c653a-359">That is because a decision trees model ideally splits on the most important attributes first.</span></span>  
  
 <span data-ttu-id="c653a-360">計算分岔準則的方式有很多，端視您選擇的演算法參數而定。</span><span class="sxs-lookup"><span data-stu-id="c653a-360">There are many ways of calculating a score for a split, depending on the algorithm parameter you choose.</span></span> <span data-ttu-id="c653a-361">如何針對每個計分方法計算分數不在本主題的討論範圍內。</span><span class="sxs-lookup"><span data-stu-id="c653a-361">A discussion of how the scores are calculated for each of the scoring methods is beyond the scope of this topic.</span></span> <span data-ttu-id="c653a-362">如需詳細資訊，請參閱[參考資料網站上的＜](https://go.microsoft.com/fwlink/?LinkId=45963)了解 Bayesian 網路：知識與統計資料的組合 [!INCLUDE[msCoName](../../includes/msconame-md.md)] ＞。</span><span class="sxs-lookup"><span data-stu-id="c653a-362">For more information, see "[Learning Bayesian Networks: The Combination of Knowledge and Statistical Data](https://go.microsoft.com/fwlink/?LinkId=45963)", on the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Research Web site.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="c653a-363">如果您建立的決策樹模型同時擁有連續和離散的可預測屬性，您將會在 (All) 節點中看到代表每個樹狀結構類型完全不同的分數。</span><span class="sxs-lookup"><span data-stu-id="c653a-363">If you create a decision trees model that has both continuous and discrete predictable attributes, you will see completely different scores in the (All) nodes that represent each tree type.</span></span> <span data-ttu-id="c653a-364">每個模型都應該分別考量，而且用於計分迴歸的方法與用於計分分類的方法完全不同。</span><span class="sxs-lookup"><span data-stu-id="c653a-364">Each model should be considered independently, and the methods used for scoring regression are completely different from those used for scoring classification.</span></span> <span data-ttu-id="c653a-365">節點分數值無法進行比較。</span><span class="sxs-lookup"><span data-stu-id="c653a-365">The node score values cannot be compared.</span></span>  
  
##  <a name="regression-nodes-within-a-decision-tree-model"></a><a name="bkmk_RegressionNodes"></a><span data-ttu-id="c653a-366">決策樹模型中的回歸節點</span><span class="sxs-lookup"><span data-stu-id="c653a-366">Regression Nodes within a Decision Tree Model</span></span>  
 <span data-ttu-id="c653a-367">如果決策樹模型包含可預測的屬性與連續的數值資料，Microsoft 決策樹演算法會嘗試在資料中，找出已預測狀態與輸入變數間關聯性為線性的區域。</span><span class="sxs-lookup"><span data-stu-id="c653a-367">If a decision trees model contains a predictable attribute with continuous numeric data, the Microsoft Decision Trees algorithm seeks to find areas in the data where the relationship between the predicted state and the input variables is linear.</span></span> <span data-ttu-id="c653a-368">如果演算法成功找出線性關聯性，該演算法就會建立一個代表線性迴歸的特殊樹狀結構 (NODE_TYPE = 25)。</span><span class="sxs-lookup"><span data-stu-id="c653a-368">If the algorithm is successful in finding a linear relationship, it creates a special tree (NODE_TYPE = 25) that represents a linear regression.</span></span> <span data-ttu-id="c653a-369">這些迴歸樹狀節點比代表離散值的節點更為複雜。</span><span class="sxs-lookup"><span data-stu-id="c653a-369">These regression tree nodes are more complex than nodes that represent discrete values.</span></span>  
  
 <span data-ttu-id="c653a-370">一般而言，迴歸會將連續相依 (可預測的變數) 中的變更對應為輸入中變更的功能。</span><span class="sxs-lookup"><span data-stu-id="c653a-370">In general, a regression maps the changes in the continuous dependent (predictable variable) as a function of changes in the inputs.</span></span> <span data-ttu-id="c653a-371">如果相依變數有任何連續輸入，而且輸入和已預測值之間的關聯性夠穩定，可以當做線條圖計算，迴歸的節點就會包含公式。</span><span class="sxs-lookup"><span data-stu-id="c653a-371">If the dependent variable has any continuous inputs, and the relationship between the input and predicted value is stable enough to be computed as a line graph, the node for the regression contains a formula.</span></span>  
  
 <span data-ttu-id="c653a-372">不過，如果輸入和已預測值之間的關聯性為 *「非線性的」*(Nonlinear)，就會建立分岔，如同標準決策樹一樣。</span><span class="sxs-lookup"><span data-stu-id="c653a-372">However, if the relationship between the input and predicted value is *nonlinear*, a split is created instead, just like a standard decision tree.</span></span> <span data-ttu-id="c653a-373">例如，假設 A 是可預測的屬性，而 B 和 C 是輸入，其中 C 是連續的值類型。</span><span class="sxs-lookup"><span data-stu-id="c653a-373">For example, assume that A is the predictable attribute, and B and C are the inputs, where C is a continuous value type.</span></span> <span data-ttu-id="c653a-374">如果 A 和 C 之間的關聯性在部分資料中相當穩定，但在部分資料中並不穩定，此演算法將會建立分岔來表示不同的資料區域。</span><span class="sxs-lookup"><span data-stu-id="c653a-374">If the relationship between A and C is fairly stable in parts of the data, but unstable in others, the algorithm will create splits to represent the different areas of the data.</span></span>  
  
|<span data-ttu-id="c653a-375">分岔條件</span><span class="sxs-lookup"><span data-stu-id="c653a-375">Split condition</span></span>|<span data-ttu-id="c653a-376">節點的結果</span><span class="sxs-lookup"><span data-stu-id="c653a-376">Result in node</span></span>|  
|---------------------|--------------------|  
|<span data-ttu-id="c653a-377">如果 n \< 5</span><span class="sxs-lookup"><span data-stu-id="c653a-377">if n \< 5</span></span>|<span data-ttu-id="c653a-378">關聯性可以表示為方程式 1</span><span class="sxs-lookup"><span data-stu-id="c653a-378">Relationship can be expressed as equation 1</span></span>|  
|<span data-ttu-id="c653a-379">如果 n 介於 5 和 10 之間</span><span class="sxs-lookup"><span data-stu-id="c653a-379">if n between 5 and 10</span></span>|<span data-ttu-id="c653a-380">無方程式</span><span class="sxs-lookup"><span data-stu-id="c653a-380">No equation</span></span>|  
|<span data-ttu-id="c653a-381">如果 n > 10</span><span class="sxs-lookup"><span data-stu-id="c653a-381">if n > 10</span></span>|<span data-ttu-id="c653a-382">關聯性可以表示為方程式 2</span><span class="sxs-lookup"><span data-stu-id="c653a-382">Relationship can be expressed as equation 2</span></span>|  
  
 <span data-ttu-id="c653a-383">如需迴歸節點的詳細資訊，請參閱[線性迴歸模型的採礦模型內容 &#40;Analysis Services - 資料採礦&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md)。</span><span class="sxs-lookup"><span data-stu-id="c653a-383">For more information about regression nodes, see [Mining Model Content for Linear Regression Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md).</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="c653a-384">另請參閱</span><span class="sxs-lookup"><span data-stu-id="c653a-384">See Also</span></span>  
 <span data-ttu-id="c653a-385">[&#40;Analysis Services 的採礦模型內容-資料採礦&#41;](mining-model-content-analysis-services-data-mining.md) </span><span class="sxs-lookup"><span data-stu-id="c653a-385">[Mining Model Content &#40;Analysis Services - Data Mining&#41;](mining-model-content-analysis-services-data-mining.md) </span></span>  
 <span data-ttu-id="c653a-386">[資料採礦模型檢視器](data-mining-model-viewers.md) </span><span class="sxs-lookup"><span data-stu-id="c653a-386">[Data Mining Model Viewers](data-mining-model-viewers.md) </span></span>  
 <span data-ttu-id="c653a-387">[資料採礦查詢](data-mining-queries.md) </span><span class="sxs-lookup"><span data-stu-id="c653a-387">[Data Mining Queries](data-mining-queries.md) </span></span>  
 [<span data-ttu-id="c653a-388">Microsoft 決策樹演算法</span><span class="sxs-lookup"><span data-stu-id="c653a-388">Microsoft Decision Trees Algorithm</span></span>](microsoft-decision-trees-algorithm.md)  
  
  
